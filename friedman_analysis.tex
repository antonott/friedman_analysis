\documentclass{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{enumitem}
\usepackage{array}

\DeclareMathOperator{\vspan}{span}

\newcommand{\bb}[1]{\mathbb{#1}}
\newcommand{\norm}[1]{{\lVert #1 \rVert}}
\newcommand{\snorm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\brac}[1]{\langle #1 \rangle}

\let\sc\relax
\newcommand{\sc}[1]{\mathscr{#1}}

\let\cal\relax
\newcommand{\cal}[1]{\mathcal{#1}}

\theoremstyle{remark}
\newtheorem*{solution}{Solution}

\setenumerate{listparindent=\parindent, parsep=0pt}

\title{Notes for \textit{Foundations of Modern Analysis} by Avner Friedman}
\author{Anton Ottosson -- antonott@kth.se}
\date{\today}

\begin{document}

\maketitle

\chapter*{Chapter 1 -- Measure Theory}

\section*{Section 1.1 -- Rings and Algebras}

\subsection*{Problems}

\subsubsection*{1.1.1}
\begin{equation*}
  \left( \varliminf_n E_n \right)^c = \varlimsup_n E_n^c, \quad \left( \varlimsup_n E_n \right)^c = \varliminf_n E_n^c.
\end{equation*}

\begin{solution}
  Note that
  \begin{equation*}
    \begin{split}
      x \in \varliminf_n E_n &\iff \text{$x \in E_n$ for all but finitely many $n$} \\
      &\iff \text{$x \in E_n^c$ for only finitely many $n$}.
    \end{split}
  \end{equation*}
  Hence
  \begin{equation*}
    \begin{split}
      x \in \left( \varliminf_n E_n \right)^c &\iff \text{$x \in E_n^c$ for infinitely many $n$} \\
      &\iff x \in \varlimsup_n E_n^c,
    \end{split}
  \end{equation*}
  proving the first identity.

  Next, let $F_n = E_n^c$ for every $n$. Then
  \begin{equation*}
    \varlimsup_n E_n = \varlimsup_n F_n^c = \left( \varliminf_n F_n \right)^c = \left( \varliminf_n E_n^c \right)^c
  \end{equation*}
  by the first identity, and the second identity follows.
\end{solution}

\subsubsection{1.1.2}
\begin{equation*}
  \varlimsup_n E_n = \bigcap_{k=1}^\infty \bigcup_{n=k}^\infty E_n, \quad \varliminf_n E_n = \bigcup_{k=1}^\infty \bigcap_{n=k}^\infty E_n.
\end{equation*}

\begin{solution}
  Suppose $x \in \varlimsup_n E_n$. Then $x \in E_n$ for infinitely many $n$. It follows that $x \in \bigcup_{n=k}^\infty E_n$ for all $k \in \bb N$, and hence that $x \in \bigcap_{k=1}^\infty \bigcup_{n=k}^\infty E_n$.

  Conversely, assume that $x \in \bigcap_{k=1}^\infty \bigcup_{n=k}^\infty E_n$. Then $x \in \bigcup_{n=k}^\infty E_n$ for all $k \in \bb N$. It follows that $x \in E_n$ for infinitely many $n$, and thus that $x \in \varlimsup_n E_n$. This proves the first identity.

  Next, suppose that $x \in \varliminf_n E_n$. Then $x \in E_n$ for all but finitely many $n$, so there is some $k' \in \bb N$ such that $x \in E_n$ for all $n \ge k'$. It follows that $x \in \bigcap_{n=k'}^\infty E_n$, and hence that $x \in \bigcup_{k=1}^\infty \bigcap_{n=k}^\infty E_n$.

  Conversely, assume that $x \in \bigcup_{k=1}^\infty \bigcap_{n=k}^\infty E_n$. Then $x \in \bigcap_{n=k'}^\infty E_n$ for some $k' \in \bb N$, which means that $x \in E_n$ for all $n \ge k'$. It follows that $x \in E_n$ for all but finitely many $n$; that is, $x \in \varliminf_n E_n$.
\end{solution}

\subsubsection*{1.1.3}
If $\sc R$ is a $\sigma$-ring and $E_n \in \sc R$, then
\begin{equation*}
  \bigcap_{n=1}^\infty E_n \in \sc R, \quad \varlimsup_n E_n \in \sc R, \quad \varliminf_n E_n \in \sc R.
\end{equation*}

\begin{solution}
  Note that
  \begin{equation*}
    \bigcap_{n=1}^\infty E_n = E_1 \cap \left( \bigcap_{n=1}^\infty E_n \right) = E_1 - \left( E_1 - \bigcap_{n=1}^\infty E_n \right),
  \end{equation*}
  and that
  \begin{equation*}
    E_1 - \bigcap_{n=1}^\infty E_n = \bigcup_{n=1}^\infty (E_1 - E_n) \in \sc R,
  \end{equation*}
  using one of De Morgan's laws along with properties (b) and (e). It follows (by (b) again) that $\bigcap_{n=1}^\infty E_n \in \sc R$. That is, $\sc R$ is closed under countable intersections.

  Given $k \in \bb N$, let $A_n = \varnothing$ for $n < k$, and let $A_n = E_n$ for $n \ge k$. Then $A_n \in \sc R$ for all $n$ by (a), hence
  \begin{equation*}
    \bigcup_{n=k}^\infty E_n = \bigcup_{n=1}^\infty A_n \in \sc R
  \end{equation*}
  by (e). Since $\sc R$ is closed under countable intersections, we then have
  \begin{equation*}
    \varlimsup_n E_n = \bigcap_{k=1}^\infty \bigcup_{n=k}^\infty E_n \in \sc R.
  \end{equation*}

  By a similar argument we find that
  \begin{equation*}
    \bigcap_{n=k}^\infty E_n \in \sc R
  \end{equation*}
  for all $k \in \bb N$. Thus
  \begin{equation*}
    \varliminf_n E_n = \bigcup_{k=1}^\infty \bigcap_{n=k}^\infty E_n \in \sc R
  \end{equation*}
  by (e).
\end{solution}

\subsubsection*{1.1.4}
The intersection of any collection of rings (algebras, $\sigma$-rings, or $\sigma$-algebras) is also a ring (an algebra, $\sigma$-ring, or $\sigma$-algebra).

\begin{solution}
  Let $\sc C$ be a collection of classes. Let $\bigcap \sc C$ denote the intersection of all classes in $\sc C$. We will show that if one of the properties (a)-(e) is satisfied by all classes in $\sc C$, then $\bigcap \sc C$ satisfies that property as well. The result requested in the problem then follows as an immediate corollary.

  It is clear that if every $\sc R \in \sc C$ satisfies (a), then so does $\bigcap \sc C$. Suppose every $\sc R \in \sc C$ satisfies (b). If $A,B \in \bigcap \sc C$ then $A,B \in \sc R$ for every $\sc R \in \sc C$. Hence $A - B \in \sc R$ for all $\sc R \in \sc C$, and it follows that $A - B \in \bigcap \sc C$. The argument for (c) is similar (with $A \cup B$ in place of $A - B$), and (d) is obvious.

  Finally, suppose that every $\sc R \in \sc C$ satisfies (e). If $A_1, A_2, \dotsc \in \bigcap \sc C$ then $A_1, A_2, \dotsc \in \sc R$ for every $\sc R \in \sc C$. Hence $\bigcup_{n=1}^\infty A_n \in \sc R$ for all $\sc R \in \sc C$, and it follows that $\bigcup_{n=1}^\infty A_n \in \bigcap \sc C$.
\end{solution}

\subsubsection*{1.1.5}
If $\sc D$ is any class of sets, then there exists a unique ring $\sc R_0$ such that (i) $\sc R_0 \supset \sc D$, and (ii) any ring $\sc R$ containing $\sc D$ contains also $\sc R_0$. $\sc R_0$ is called the \emph{ring generated} by $\sc D$, and is denoted by $\sc R(\sc D)$.

\begin{solution}
  Let $\sc R_0$ be the intersection of all rings containing $\sc D$. This is a ring by the previous exercise, and it satisfies the properties (i) and (ii). To see that it is unique, let $\sc R_0'$ also by a ring satisfying (i) and (ii). Then $\sc R_0 \subset \sc R_0'$ and $\sc R_0' \subset \sc R_0$ by property (ii), so $\sc R_0 = \sc R_0'$.
\end{solution}

\subsubsection*{1.1.6}
If $\sc D$ is any class of sets, then there exists a unique $\sigma$-ring $\sc S_0$ such that (i) $\sc S_0 \supset \sc D$, and (ii) any $\sigma$-ring containing $\sc D$ contains also $\sc S_0$. We call $\sc S_0$ the \emph{$\sigma$-ring generated} by $\sc D$, and denote it by $\sc S(\sc D)$. A similar result holds for $\sigma$-algebras, and we speak of the \emph{$\sigma$-algebra generated} by $\sc D$.

\begin{solution}
  By the same argument as in the previous exercise, $\sc S_0$ is the intersection of all $\sigma$-rings containing $\sc D$. Similarly the $\sigma$-algebra generated by $\sc D$ is the intersection of all $\sigma$-algebras containing $\sc D$.
\end{solution}

\subsubsection*{1.1.7}
If $\sc D$ is any class of sets, then every set in $\sc R(\sc D)$ can be covered by (that is, is contained in) a finite union of sets of $\sc D$. [\emph{Hint:} The class $\sc K$ of sets that can be covered by finite unions of sets of $\sc D$ forms a ring.]

\begin{solution}
  Let $\sc K$ be the class of all sets that can be covered by a finite union of sets in $\sc D$. Certainly $\varnothing \in \sc K$, since $\varnothing$ is a subset of the empty union. If $A, B \in \sc K$, then
  \begin{equation*}
    A \subset \bigcup_{i=1}^m E_i, \quad B \subset \bigcup_{i=1}^n F_i,
  \end{equation*}
  for some sets $E_1, \dots, E_m, F_1, \dots, F_n \in \sc D$. (Note that $m$ or $n$ can be zero, in which case the corresponding union is empty.) Thus
  \begin{equation*}
    A - B \subset A \subset \bigcup_{i=1}^m E_i
  \end{equation*}
  and
  \begin{equation*}
    A \cup B \subset \left( \bigcup_{i=1}^m E_i \right) \cup \left( \bigcup_{j=1}^n F_j \right),
  \end{equation*}
  so both $A - B$ and $A \cup B$ are elements of $\sc K$.

  The above shows that $\sc K$ is a ring, and certainly $\sc D \subset \sc K$. Hence $\sc R(\sc D) \subset \sc K$ by Problem 1.1.5, and it follows that every set in $\sc R(\sc D)$ can be covered by a finite union of sets in $\sc D$.
\end{solution}

\section*{Section 1.2 -- Definition of Measure}

\subsection*{Problems}

\subsubsection*{1.2.1}
If $\mu$ satisfies the properties (i)-(iii) in Definition 1.2.1, and if $\mu(E) < \infty$ for at least one set $E$, then (iv) is also satisfied.

\begin{solution}
  We have
  \begin{equation*}
    \mu(E) = \mu(E \cup \varnothing) = \mu(E) + \mu(\varnothing),
  \end{equation*}
  hence $\mu(\varnothing) = 0$.
\end{solution}

\subsubsection*{1.2.2}
Let $X$ be an infinite space. Let $\cal A$ be the class of all subsets of $X$. Define $\mu(E) = 0$ if $E$ is finite and $\mu(E) = \infty$ if $E$ is infinite. Then $\mu$ is finitely additive but not completely additive.

\begin{solution}
  Suppose $A, B \in \cal A$. Note that $A \cup B$ is finite if both $A$ and $B$ are finite, but infinite otherwise. Hence
  \begin{equation*}
    \mu(A \cup B) = 0 = \mu(A) + \mu(B)
  \end{equation*}
  in the former case, and
  \begin{equation*}
    \mu(A \cup B) = \infty = \mu(A) + \mu(B)
  \end{equation*}
  in the latter. This proves that $\mu$ is additive; \emph{finite} additivity follows by a simple induction argument.

  Let $(x_n)$ be a sequence of distinct points in $X$. Then $\bigcup_{n=1}^\infty \{x_n\}$ is an infinite set, so
  \begin{equation*}
    \mu \left( \bigcup_{n=1}^\infty \{x_n\} \right) = \infty,
  \end{equation*}
  but
  \begin{equation*}
    \sum_{n=1}^\infty \mu(\{x_n\}) = 0.
  \end{equation*}
  Thus $\mu$ is not completely additive.
\end{solution}

\subsubsection*{1.2.3}
If $\mu$ is a measure on a $\sigma$-algebra $\cal A$, and if $E$, $F$ are sets of $\cal A$, then
\begin{equation*}
  \mu(E) + \mu(F) = \mu(E \cup F) + \mu(E \cap F).
\end{equation*}

\begin{solution}
  If $\mu(F) = \infty$, then $\mu(E \cup F) = \infty$ by Theorem 1.2.1(i), and the given equality holds. If $\mu(F) < \infty$, then
  \begin{equation*}
    \begin{split}
      \mu(E \cup F) &= \mu[E \cup (F - (E \cap F))] \\
      &= \mu(E) + \mu[F - (E \cap F)] \\
      &= \mu(E) + \mu(F) - \mu(E \cap F),
    \end{split}
  \end{equation*}
  with the last equality following from Theorem 1.2.1(ii). Note that $E \cap F \subset F$ so that $\mu(E \cap F) \le \mu(F) < \infty$. Hence we can rearrange the above to yield
  \begin{equation*}
    \mu(E) + \mu(F) = \mu(E \cup F) + \mu(E \cap F).
  \end{equation*}
\end{solution}

\subsubsection*{1.2.6}
Give an example of a measure $\mu$ and a monotone-decreasing sequence $\{E_n\}$ of $\cal A$ such that $\mu(E_n) = \infty$ for all $n$, and $\mu(\lim_n E_n) = 0$.

\begin{solution}
  Let $X = \bb R$ and let $\cal A = \cal P(\bb R)$ (the power set of $\bb R$; this is easily seen to be a $\sigma$-algebra). Define $\mu: \cal A \to [0,\infty]$ such that $\mu(E)$ is the number of points in $E$ (with $\mu(E) = \infty$ if $E$ is infinite). This is easily seen to be a measure.

  For each $n \in \bb N$, let $E_n = (0, 1/n)$. Then $(E_n)$ is a monotone decreasing sequence of sets in $\cal A$, $\mu(E_n) = \infty$ for all $n$, and
  \begin{equation*}
    \mu \left( \lim_n E_n \right) = \mu \left( \bigcap_{n=1}^\infty E_n \right) = \mu(\varnothing) = 0.
  \end{equation*}
\end{solution}

\section*{Section 1.3 -- Outer Measure}

\subsection*{Problems}

\subsubsection*{1.3.1}
Define $\mu^*(E)$ as the number of points in $E$ if $E$ is finite and $\mu^*(E) = \infty$ if $E$ is infinite. Show that $\mu^*$ is an outer measure. Determine the measurable sets.

\begin{solution}
  Of the properties listed in Definition 1.3.1, only countable subadditivity is non-obvious for $\mu^*$. But let us start with proving finite subadditivity.

  Let $A$ and $B$ be sets. If either is infinite, then so is $A \cup B$, hence
  \begin{equation*}
    \mu^*(A \cup B) = \infty = \mu^*(A) + \mu^*(B).
  \end{equation*}
  If both $A$ and $B$ are finite sets, then
  \begin{equation*}
    \mu^*(A \cup B) = \mu^*(A) + \mu^*(B - A) \le \mu^*(A) + \mu^*(B)
  \end{equation*}
  by basic set-theoretic considerations. Thus $\mu^*$ is subadditive, and finite subadditivity follows by induction on the number of sets in the union.

  Now, let $(E_n)$ be a sequence of sets. If infinitely many of the sets $E_n$ are nonempty, then $\sum_n \mu^*(E_n) = \infty$, and
  \begin{equation*}
    \mu^*\left( \bigcup_n E_n \right) \le \sum_n \mu^*(E_n)
  \end{equation*}
  follows. If only finitely many of the sets $E_n$ are nonempty, let $E_{n_1}, E_{n_2}, \dots, E_{n_k}$ be those sets. Then
  \begin{equation*}
    \mu^*\left( \bigcup_{n=1}^\infty E_n \right) = \mu^*\left( \bigcup_{i=1}^k E_{n_i} \right) \le \sum_{i=1}^k \mu^*(E_{n_i}) = \sum_{n=1}^\infty \mu^*(E_n),
  \end{equation*}
  by finite subadditivity. This proves that $\mu^*$ is countably subadditive, and hence that $\mu^*$ is an outer measure.

  Note that $\mu^*$ is \emph{additive} on disjoint sets; if $A \cap B = \varnothing$, then $\mu^*(A \cup B) = \mu^*(A) + \mu^*(B)$. In particular,
  \begin{equation*}
    \mu^*(A) = \mu^*(A \cap E) + \mu^*(A - E)
  \end{equation*}
  for all sets $A, E$. That is, all sets are measurable.
\end{solution}

\subsubsection*{1.3.2}
Define $\mu^*(\varnothing) = 0$, $\mu^*(E) = 1$ if $E \ne \varnothing$. Show that $\mu^*$ is an outer measure, and determine the measurable sets.

\begin{solution}
  As in the previous excercise, the only slightly non-obvious property is countable subadditivity. Hence, let $(E_n)$ be a sequence of sets. If all the sets $E_n$ are empty, then certainly
  \begin{equation*}
    \mu^* \left( \bigcup_n E_n \right) = 0 = \sum_{n} \mu^*(E_n).
  \end{equation*}
  If not, then there is some $m$ such that $E_m \ne \varnothing$, and it follows that
  \begin{equation*}
    \mu^* \left( \bigcup_n E_n \right) = 1 = \mu^*(E_m) \le \sum_n \mu^*(E_n).
  \end{equation*}
  Thus $\mu^*$ is indeed countably subadditive, and therefore also an outer measure.

  The empty set is measurable:
  \begin{equation*}
    \mu^*(A \cap \varnothing) + \mu^*(A - \varnothing) = \mu^*(\varnothing) + \mu^*(A) = \mu^*(A)
  \end{equation*}
  for all sets $A$. It follows by Theorem 1.3.1 that $X$ is measurable as well (the measurable sets make up a $\sigma$-algebra). Indeed $\varnothing$ and $X$ are the only measurable sets. To see this, let $E$ be any set other than those two (this requires that $X$ contains at least two elements). Then both $E$ and $E^c$ are nonempty, so
  \begin{equation*}
    \mu^*(X \cap E) + \mu^*(X - E) = \mu^*(E) + \mu^*(E^c) = 2 > 1 = \mu^*(X).
  \end{equation*}
\end{solution}


\section*{Section 1.4 -- Construction of Outer Measures}

\subsection*{Problems}

\subsubsection*{1.4.4}
If $\sc K$ is a $\sigma$-algebra and $\lambda$ is a measure on $\sc K$, then $\mu^*(A) = \lambda(A)$ for any $A \in \sc K$. [\emph{Hint:} $\mu^*(A) = \inf \{\lambda(E); E \in \sc K, E \supset A\}$.]

\begin{solution}
  Note that the description of $\mu^*$ can be simplified when $\sc K$ is a $\sigma$-algebra and $\lambda$ is a measure. For suppose that $A \subset X$, $E_n \in \sc K \; (n = 1, 2, \dots$), and $A \subset \bigcup_n E_n$. Then $E := \bigcup_n E_n \in \sc K$, and $\lambda(E) \le \sum_n \lambda(E_n)$ by Theorem 1.2.2. Hence
  \begin{equation*}
    \mu^*(A) = \inf \{\lambda(E); E \in \sc K, E \supset A\}.
  \end{equation*}

  Now, suppose that $A \in \sc K$. Certainly $\lambda(A)$ is an element of $\{\lambda(E); E \in \sc K, E \supset A\}$. And if $E \in \sc K$ and $E \supset A$, then $\lambda(E) \ge \lambda(A)$ by Theorem 1.2.1(i). Thus
  \begin{equation*}
    \lambda(A) = \inf \{\lambda(E); E \in \sc K, E \supset A\} = \mu^*(A).
  \end{equation*}
\end{solution}

\subsubsection*{1.4.5}
If $\sc K$ is a $\sigma$-algebra and $\lambda$ is a measure on $\sc K$, then every set in $\sc K$ is $\mu^*$-measurable.

\begin{solution}
  Recall the simplified description of $\mu^*$ from the previous problem. Let $E \in \sc K$ and $A \subset X$. For every $\epsilon > 0$ there exists $F \in \sc K$ such that $F \supset A$ and
  \begin{equation*}
    \mu^*(A) + \epsilon > \lambda(F);
  \end{equation*}
  else $\mu^*(A)$ would not be the greatest lower bound of $\{\lambda(E); E \in \sc K, E \supset A\}$. Moreover,
  \begin{equation*}
    \lambda(F) = \lambda(F \cap E) + \lambda(F - E)
  \end{equation*}
  since $\lambda$ is a measure on $\sc K$,
  \begin{equation*}
    \lambda(F \cap E) + \lambda(F - E) = \mu^*(F \cap E) + \mu^*(F - E) 
  \end{equation*}
  by what we found in the previous exercise, and finally
  \begin{equation*}
    \mu^*(F \cap E) + \mu^*(F - E) \ge \mu^*(A \cap E) + \mu^*(A - E)
  \end{equation*}
  by monotonicity of the outer measure $\mu^*$. Putting all of this together, we have
  \begin{equation*}
    \mu^*(A) + \epsilon > \mu^*(A \cap E) + \mu^*(A - E)
  \end{equation*}
  for all $\epsilon > 0$, and thus
  \begin{equation*}
    \mu^*(A) \ge \mu^*(A \cap E) + \mu^*(A - E).
  \end{equation*}
  It follows that every set $E \in \sc K$ is $\mu^*$-measurable.
\end{solution}


\section*{Section 1.6 -- The Lebesgue and the Lebesgue-Stieltjes Measures}

\subsection*{Problems}

\subsubsection*{1.6.3}
The outer Lebesgue measure of a closed bounded interval $[a,b]$ on the real line is equal to $b-a$. [\emph{Hint:} Use the Heine-Borel theorem to replace a countable covering by a finite covering.]

\begin{solution}
  Suppose $(E_n)$ is a sequence of elements of $\sc K$ (i.e.\ a sequence of open intervals) such that $[a,b] \subset \bigcup_{n=1}^\infty E_n$. The collection $\{E_n\}$ constitutes an \emph{open cover} of $[a,b]$. By the Heine-Borel theorem $[a,b]$ is compact, hence there exists a \emph{finite subcover} $\{E_{n_1}, \dots, E_{n_k}\}$, such that $[a,b] \subset \bigcup_{i=1}^k E_{n_i}$.

  Assume without loss of generality that $E_{n_i} \cap [a,b] \ne \varnothing$ for all $i$; otherwise we can simply remove those $E_{n_i}$ that are disjoint with $[a,b]$ and still have a finite subcover. Write $E_{n_i} = (a_i, b_i)$ for each $i$, and define
  \begin{equation*}
    \alpha = \min\{a_1, \dots, a_k\}, \quad \beta = \max\{b_1, \dots, b_k\}.
  \end{equation*}
  It is clear that $\alpha$ and $\beta$ are the infimum and supremum, respectively, of $\bigcup_{i=1}^k E_{n_i}$. Note that $\alpha = a_j$ for some $j$, and $a_j < a < b_j$ since $E_{n_j}$ and $[a,b]$ have nonempty intersection. Thus $(\alpha, a] \subset \bigcup_{i=1}^k E_{n_i}$, and similarly $[b, \beta) \subset \bigcup_{i=1}^k E_{n_i}$. It follows that
  \begin{equation*}
    \bigcup_{i=1}^k E_{n_i} = (\alpha, \beta) \in \sc K.
  \end{equation*}

  Finally note that $\lambda$ is finitely subadditive. (This is easily proven with induction.) (TODO: This is not convincing; use better proof from Rosenthal notes.) Thus,
  \begin{equation*}
    \sum_{n=1}^\infty \lambda(E_n) \ge \sum_{i=1}^k \lambda(E_{n_i}) \ge \lambda\left[ (\alpha, \beta) \right] = \beta - \alpha > b - a.
  \end{equation*}
  It follows that $b - a$ is a lower bound of the set
  \begin{equation*}
    \Lambda([a,b]) := \left\{ \sum_{n=1}^\infty \lambda(E_n); \, E_n \in \sc K, \, \bigcup_{n=1}^\infty E_n \supset [a,b] \right\}.
  \end{equation*}
  Moreover, for every $\epsilon > 0$ we have
  \begin{equation*}
    [a,b] \subset \left( a - \frac{\epsilon}{2}, b + \frac{\epsilon}{2} \right) \in \sc K
  \end{equation*}
  and
  \begin{equation*}
    \lambda \left[ \left( a - \frac{\epsilon}{2}, b + \frac{\epsilon}{2} \right) \right] = b - a + \epsilon.
  \end{equation*}
  Hence $b - a$ is the \emph{greatest} lower bound of $\Lambda([a,b])$, and $\mu^*([a,b]) = b - a$.
\end{solution}

\subsubsection*{1.6.4}
The outer Lebesgue measure of each of the intervals $(a,b), [a,b), (a,b]$ is equal to $b-a$.

\begin{solution}
  Recall that $\mu^*$ is monotone, on account of being an outer measure. Hence $\mu^*[(a,b)] \le \mu^*([a,b]) = b - a$, the latter equality being the result of the previous problem. Moreover, for all $\epsilon \in (0, b-a)$ we have
  \begin{equation*}
    \left[ a + \frac{\epsilon}{2}, b - \frac{\epsilon}{2} \right] \subset (a,b),
  \end{equation*}
  so that
  \begin{equation*}
    \mu^*[(a,b)] \ge \mu^* \left( \left[ a + \frac{\epsilon}{2}, b - \frac{\epsilon}{2} \right] \right) = b - a - \epsilon.
  \end{equation*}
  Thus $\mu^*[(a,b)] \ge b - a$, and it follows that $\mu^*[(a,b)] = b - a$.

  The outer measures of $[a,b)$ and $(a,b]$ follow immediately by monotonicity:
  \begin{equation*}
    \mu^*[(a,b)] \le \mu^*([a,b)) \le \mu^*([a,b]),
  \end{equation*}
  so that $\mu^*([a,b)) = b - a$. Similarly for $(a,b]$.
\end{solution}

\subsubsection*{1.6.5}
Consider the transformation $T x = \alpha x + \beta$ from the real line onto itself, where $\alpha, \beta$ are real numbers and $\alpha \ne 0$. It maps sets $E$ onto sets $T(E)$. Denote by $\mu$ ($\mu^*$) the Lebesgue measure (outer measure) on the real line. Prove
\begin{enumerate}[label=(\alph*)]
  \item For any set $E$, $\mu^*(T(E)) = |\alpha| \mu^*(E)$.
  \item $E$ is Lebesgue-measurable if and only if $T(E)$ is Lebesgue-measureable.
  \item If $E$ is Lebesgue-measurable, then $\mu(T(E)) = |\alpha| \mu(E)$.
\end{enumerate}

\begin{solution}
  Let us start with a couple of simple observations:
  \begin{itemize}
    \item $T$ is bijective, with inverse given by
      \begin{equation*}
        T^{-1}(x) = \frac{x - \beta}{\alpha}.
      \end{equation*}
    \item Suppose $I = (a,b)$. Then
      \begin{equation*}
        T(I) = (\alpha a + \beta, \alpha b + \beta)
      \end{equation*}
      if $\alpha > 0$, and
      \begin{equation*}
        T(I) = (\beta b + \beta, \alpha a + \beta)
      \end{equation*}
      if $\alpha < 0$. Either way,
      \begin{equation*}
        \mu^*[T(I)] = |\alpha| (b - a) = |\alpha| \mu^*(I),
      \end{equation*}
      where we have used one of the results of the previous exercise. Similarly, $T^{-1}(I)$ is an open interval and
      \begin{equation*}
        \mu^*[T^{-1}(I)] = |\alpha|^{-1} \mu^*(I).
      \end{equation*}
      Of course, the latter two identities still hold if $I = \varnothing$. Hence they hold for all $I \in \sc K$.
  \end{itemize}
  Also, let us use the notation
  \begin{equation*}
    \Lambda(E) = \left\{ \sum_{n=1}^\infty \lambda(I_n); \, I_n \in \sc K, \, \bigcup_{n=1}^\infty I_n \supset E \right\}
  \end{equation*}
  for all $E \subset \bb R$.

  \begin{enumerate}[label=(\alph*)]
    \item Suppose $(I_n)$ is a sequence in $\sc K$ (i.e.\ a sequence of open intervals) and $E \subset \bigcup_n I_n$. Then $T(I_n) \in \sc K$ for every $n$,
      \begin{equation*}
        T(E) \subset T \left( \bigcup_n I_n \right) = \bigcup_n T(I_n),
      \end{equation*}
      and
      \begin{equation*}
        \sum_n \lambda[T(I_n)] = |\alpha| \sum_n \lambda(I_n).
      \end{equation*}
      Thus, if $s \in \Lambda(E)$, then $|\alpha| s \in \Lambda[T(E)]$. It follows that
      \begin{equation*}
        \mu^*[T(E)] = \inf \Lambda[T(E)] \le |\alpha| \inf \Lambda(E) = |\alpha| \mu^*(E).
      \end{equation*}

      Conversely, suppose $(J_n)$ is a sequence in $\sc K$ and $T(E) \subset \bigcup_n J_n$. Then $T^{-1}(J_n) \in \sc K$ for all $n$,
      \begin{equation*}
        E = T^{-1}[T(E)] \subset T^{-1} \left( \bigcup_n J_n \right) = \bigcup_n T^{-1}(J_n),
      \end{equation*}
      and
      \begin{equation*}
        \sum_n \lambda[T^{-1}(J_n)] = |\alpha|^{-1} \sum_n \lambda(J_n).
      \end{equation*}
      Hence, by the same logic as above, we find that $\mu^*(E) \le |\alpha|^{-1} \mu^*[T(E)]$, and it follows that
      \begin{equation*}
        \mu^*[T(E)] = |\alpha| \mu^*(E).
      \end{equation*}

    \item Note that if $f: X \to Y$ is a bijective function (between arbitrary sets $X,Y$), then
      \begin{equation*}
        \begin{split}
          f^{-1}[f(A)] &= A, \\
          f(A \cup B) &= f(A) \cup f(B), \\
          f(A - B) &= f(A) - f(B), \\
          f[f^{-1}(C)] &= C, \\
        \end{split}
      \end{equation*}
      for all $A, B \subset X$ and $C \subset Y$.

      Suppose that $E$ is measureable:
      \begin{equation*}
        \mu^*(A) = \mu^*(A \cap E) + \mu^*(A - E)
      \end{equation*}
      for all $A \subset \bb R$. Then, for all $B \subset \bb R$, we have
      \begin{equation*}
        \begin{split}
          \mu^*[B \cap T(&E)] + \mu^*[B - T(E)] \\
          &= \mu^*[T(T^{-1}(B) \cap E)] + \mu^*[T(T^{-1}(B) - E)] \\
          &= |\alpha| \mu^*[T^{-1}(B) \cap E] + |\alpha| \mu^*[T^{-1}(B) - E] \\
          &= |\alpha| \mu^*[T^{-1}(B)] \\
          &= \mu^*(B),
        \end{split}
      \end{equation*}
      so that $T(E)$ is measurable.

      Conversely, suppose that $T(E)$ is measurable. Then, for all $A \subset \bb R$,
      \begin{equation*}
        \begin{split}
          \mu^*(A \cap E&) + \mu^*(A - E) \\
          &= \mu^*[T^{-1}(T(A) \cap T(E))] + \mu^*[T^{-1}(T(A) - T(E))] \\
          &= |\alpha|^{-1} \mu^*[T(A) \cap T(E)] + |\alpha|^{-1} \mu^*[T(A) - T(E)] \\
          &= |\alpha|^{-1} \mu^*[T(A)] \\
          &= \mu^*(A),
        \end{split}
      \end{equation*}
      so that $E$ is measurable.

    \item This is immediate given (a), (b), and the definition of the Lebesgue-measure. First, $T(E)$ is Lebesgue-measurable by (b). Next, $\mu(E) = \mu^*(E)$ and $\mu[T(E)] = \mu^*[T(E)]$ since $\mu$ is simply the restriction of $\mu^*$ to the measurable sets. Finally, $\mu^*[T(E)] = |\alpha| \mu^*(E)$ by (a).
  \end{enumerate}
\end{solution}

\chapter*{Chapter 2 -- Integration}

\section*{Section 2.1 -- Definition of Measurable Functions}

\subsection*{Problems}

\subsubsection*{2.1.6}
The \emph{characteristic function} of a set $E$ is the function $\chi_E$ defined by
\begin{equation*}
  \chi_E(x) =
  \begin{cases}
    1, & \text{if $x \in E$,} \\
    0, & \text{if $x \notin E$.}
  \end{cases}
\end{equation*}
Prove that the set $E$ is measurable if and only if the function $\chi_E$ is measurable.

\begin{solution}
  Suppose $E \in \cal A$. For all $c \in \bb R$,
  \begin{equation*}
    \chi_E^{-1}\{(-\infty, c)\} = \{x \in X; \chi_E(x) < c\} =
    \begin{cases}
      \varnothing & (c \le 0), \\
      E^c & (0 < c \le 1), \\
      X & (c > 1),
    \end{cases}
  \end{equation*}
  so that $\chi_E^{-1}\{(-\infty, c)\} \in \cal A$. By Theorem 2.1.1, $\chi_E$ is measurable.

  Conversely, suppose $\chi_E$ is measurable. Then $E$ is measurable, since
  \begin{equation*}
    E = X - E^c = \chi^{-1}\{(-\infty, 2)\} - \chi^{-1}\{(-\infty, 1)\}.
  \end{equation*}
\end{solution}

\subsubsection*{2.1.9}
If $f$ is measurable, then $|f|$ and $|f|^2$ are measurable.

\begin{solution}
  If $c \le 0$, then
  \begin{equation*}
    (|f|)^{-1}\{(-\infty, c)\} = (|f|^2)^{-1}\{(-\infty, c)\} = \emptyset \in \cal A,
  \end{equation*}
  since $|f|$ and $|f|^2$ are nonnegative functions.
  
  Let $c > 0$. Then
  \begin{equation*}
    (|f|)^{-1}\{(-\infty, c)\} = \{x \in X; -c < f(x) < c\} = f^{-1}\{(-c,c)\}.
  \end{equation*}
  The set $(-c,c)$ is open, hence $f^{-1}\{(-c,c)\} \in \cal A$ by the measurability of $f$. Similarly,
  \begin{equation*}
    (|f|^2)^{-1}\{(-\infty, c)\} = f^{-1}\{(-\sqrt c, \sqrt c)\} \in \cal A.
  \end{equation*}

  Finally,
  \begin{equation*}
    (|f|)^{-1}\{+\infty\} = (|f|^2)^{-1}\{+\infty\} = f^{-1}\{+\infty\} \cup f^{-1}\{-\infty\} \in \cal A
  \end{equation*}
  by the measurability of $f$, and
  \begin{equation*}
    (|f|)^{-1}\{-\infty\} = (|f|^2)^{-1}\{-\infty\} = \emptyset \in \cal A
  \end{equation*}
  since $|f|$ and $|f|^2$ are nonnegative. Thus, both $|f|$ and $|f|^2$ are measurable by Theorem 2.1.1.
\end{solution}

\subsubsection*{2.1.10}
A monotone function defined on the real line is Lebesgue-measurable.

\begin{solution}
  Let $f$ be a monotone increasing extended real-valued function on $\bb R$;
  \begin{equation*}
    (\forall x,y \in \bb R): \quad x < y \implies f(x) \le f(y).
  \end{equation*}
  Given any $c \in \bb R$, let
  \begin{equation*}
    \xi_c = \inf \{x \in X; f(x) \ge c\}.
  \end{equation*}
  We need to consider two cases: $f(\xi_c) < c$ and $f(\xi_c) \ge c$. In the former case, $f(x) < c$ for all $x \le \xi_c$ and $f(x) \ge c$ for all $x > \xi_c$ (by monotonicity). Hence
  \begin{equation*}
    f^{-1}\{(-\infty,c)\} = (-\infty, \xi_c].
  \end{equation*}
  This is a Borel set, hence also a Lebesgue set (see Problem 1.9.3). In the latter case, $f(x) < c$ for all $x < \xi_c$ and $f(x) \ge c$ for all $x \ge \xi_c$, so that
  \begin{equation*}
    f^{-1}\{(-\infty,c)\} = (-\infty, \xi_c),
  \end{equation*}
  which is Lebesgue-measurable. Since $c$ was arbitrary, we conclude that $f$ is measurable, by Theorem 2.1.1.

  The proof for $f$ monotone decreasing is similar.
\end{solution}

\section*{Section 2.2 -- Operations on Measurable Functions}

\subsection*{Problems}

\subsubsection*{2.2.2}
Let $g(u_1, \dots, u_k)$ be a continuous function in $\bb R^k$, and let $\varphi_1, \dots, \varphi_k$ be measurable functions. Prove that the composite function $h(x) = g[\varphi_1(x), \dots, \varphi_k(x)]$ is a measurable function. Note that as a special case we may conclude that
\begin{equation*}
  \max(\varphi, \dots, \varphi_n) \quad \text{and} \quad \min(\varphi, \dots, \varphi_n)
\end{equation*}
are measurable functions.

\begin{solution}
  We will use the following fact, which may be proven in a course in topology:
  \begin{quote}
    $\bb R^k$ has a countable basis of product open subsets. Hence, if $U$ is an open subset of $\bb R^k$, then there are open subsets $U_{ni} \subset \bb R$ for $n = 1, 2, \dots$ and $i = 1, \dots, k$ such that
    \begin{equation*}
      U = \bigcup_{n=1}^\infty (U_{n1} \times \dots \times U_{nk}).
    \end{equation*}
  \end{quote}

  We are assuming that $g$ is real-valued, likewise for the functions $\varphi_i$. Let $c \in \bb R$. Note that $g^{-1}\{(-\infty,c)\}$ is open by continuity of $g$. Thus
  \begin{equation*}
    g^{-1}\{(-\infty,c)\} = \bigcup_{n=1}^\infty (U_{n1} \times \dots \times U_{nk})
  \end{equation*}
  for some open subsets $U_{ni} \subset \bb R$. Hence
  \begin{equation*}
    \begin{split}
      h^{-1}\{(-\infty,c)\} &= \{x \in X; g(\varphi_1(x), \dots, \varphi_k(x)) \le c\} \\
      &= \{x \in X; (\varphi_1(x), \dots, \varphi_k(x)) \in g^{-1}\{(-\infty,c)\}\} \\
      &= \bigcup_{n=1}^\infty \{x \in X; (\varphi_1(x), \dots, \varphi_k(x)) \in U_{n1} \times \dots \times U_{nk}\} \\
      &= \bigcup_{n=1}^\infty \bigcap_{i=1}^k \{x \in X; \varphi_i(x) \in U_{ni}\} \\
      &= \bigcup_{n=1}^\infty \bigcap_{i=1}^k \varphi_i^{-1}(U_{ni}).
    \end{split}
  \end{equation*}
  The sets $\varphi_i(U_{ni})$ are measurable since the functions $\varphi_i$ are measurable. It follows that $h^{-1}\{(-\infty,c)\}$ is measurable, and thus that $h$ is measurable, by Theorem 2.1.1.

  To apply the above to the $\max$ and $\min$ functions $\bb R^k \to \bb R$ we must show that they are continuous. Let $a < b$ and note that
  \begin{equation*}
    \begin{split}
      {\max}^{-1}\{(a,b)\} &= \{(x_1, \dots, x_k) \in \bb R^k; \text{$x_i > a$ for some $i$}\} \\
      &\quad \cap \{(x_1, \dots, x_k) \in \bb R^k; \text{$x_i < b$ for all $i$}\}.
    \end{split}
  \end{equation*}
  Both sets in the above binary intersection are easily seen to be open by considering $\epsilon$-neighborhoods about their points. It follows that $\max^{-1}(U)$ is open for all open subsets $U \in \bb R^k$, since every such $U$ can be written as a countable union of open intervals. Thus $\max$ is continuous, and one similarly shows that $\min$ is continuous.
\end{solution}

\subsubsection*{2.2.3}
Let $f(x)$ be a measurable function and define
\begin{equation*}
  g(x) =
  \begin{cases}
    \frac{1}{f(x)}, & \text{if $f(x) \ne 0$,} \\
    0, & \text{if $f(x) = 0$.}
  \end{cases}
\end{equation*}
Prove that $g$ is measurable.

\begin{solution}
  For $c < 0$,
  \begin{equation*}
    g^{-1}\{(-\infty,c)\} = \{x; 1/f(x) < c\} = \{x; 1/c < f < 0\} = f^{-1}\{(1/c, 0)\},
  \end{equation*}
  which is measurable by the measurability of $f$. Next,
  \begin{equation*}
    g^{-1}\{(-\infty,0)\} = \{x; 1/f(x) < 0\} = \{x; f(x) < 0\} = f^{-1}\{(-\infty, 0)\},
  \end{equation*}
  also measurable. Note that if we take the natural convention (unfortunately not addressed in the text) that $x/(\pm \infty) = 0$ for all $x \in \bb R$, then
  \begin{equation*}
    g^{-1}(\{0\}) = \{x; f(x) = 0\} \cup \{x; f(x) = \pm \infty\} = f^{-1}(\{0\}) \cup f^{-1}(\{\pm \infty\}).
  \end{equation*}
  Hence, for $c > 0$,
  \begin{equation*}
    \begin{split}
      g^{-1}\{(-\infty,c)\} &= g^{-1}\{(-\infty,0)\} \cup g^{-1}(\{0\}) \cup g^{-1}\{(0,c)\} \\
      &= f^{-1}\{(-\infty, 0)\} \cup f^{-1}(\{0\}) \cup f^{-1}(\{\pm \infty\}) \cup f^{-1}\{(1/c, \infty)\} \\
      &= f^{-1}\{(-\infty, 0]\} \cup f^{-1}(\{\pm \infty\}) \cup f^{-1}\{(1/c, \infty)\},
    \end{split}
  \end{equation*}
  which is measurable by the measurability of $f$ (see Problem 2.1.4). Finally, $g^{-1}(\{\pm \infty\}) = \emptyset$, and it follows by Theorem 2.1.1 that $g$ is measurable.
\end{solution}

\section*{Section 2.3 -- Egoroff's Theorem}

\subsection*{Problems}

\subsubsection*{2.3.2}
Let $\{f_n\}$ be a sequence of measurable functions in a finite measure space $X$. Suppose that for almost every $x$, $\{f_n(x)\}$ is a bounded set. Then for any $\epsilon > 0$ there exist a positive number $c$ and a measurable set $E$ with $\mu(X - E) < \epsilon$, such that $|f_n(x)| \le c$ for all $x \in E$, $n = 1,2, \dots$.

\begin{solution}
  The definition we have for `bounded set' applies to metric spaces, and it does not make much sense here since the functions $f_n$ may be extended real-valued. Hence we will assume that `$\{f_n(x)\}$ is a bounded set' means that $\sup_n |f_n(x)| < \infty$.

  Let $g = \sup_n |f_n|$, and note that $g$ is measurable by Problem 2.1.9 and Theorem 2.2.3. Let $F = \{x; \, g(x) < \infty\}$. Notice that $g(x) < \infty$ if and only if $\{f_n(x)\}$ is bounded. Hence $\mu(X - F) = 0$.

  For $k = 1,2,\dots$, define $F_k = \{x; \, g(x) \le k\}$. Then $F_1 \subset F_2 \subset \dotsm$ and $\lim_k F_k = \bigcup_{k=1}^\infty F_k = F$.  By Theorem 1.2.1(iv),
  \begin{equation*}
    \lim_k \mu(X - F_k) = \mu(X - F) = 0.
  \end{equation*}
  Given any $\epsilon > 0$, there exists a positive integer $K$ such that $\mu(X - F_k) < \epsilon$ for all $k \ge K$. In particular $\mu(X - F_K) < \epsilon$, and $g(x) \le K$ for all $x \in F_K$, which means that $|f_n(x)| \le K$ for all $x \in F_K$.
\end{solution}

\section*{Section 2.4 -- Convergence in Measure}

\subsection*{Problems}

\subsubsection*{2.4.3}
Prove the following result (which immediately yields another proof of Corollary 2.4.2): Let $f_n$ ($n = 1,2,\dots$) and $f$ be a.e.\ real-valued measurable functions in a finite measure space. For any $\epsilon > 0$, $n \ge 1$, let
\begin{equation*}
  E_n(\epsilon) = \{x; \, |f_n(x) - f(x)| \ge \epsilon\}.
\end{equation*}
Then $\{f_n\}$ converges a.e.\ to $f$ if and only if
\begin{equation*}
  \lim_{n \to \infty} \mu \left[ \bigcup_{m=n}^\infty E_m(\epsilon) \right] = 0 \quad \text{for any $\epsilon > 0$.} \tag{2.4.2}
\end{equation*}
[\emph{Hint:} Let $F = \{x; \, \text{$\{f_n(x)\}$ is not convergent to $f(x)$}\}$. Then \\ $F = \bigcup_{k=1}^\infty \varlimsup_n E_n(1/k)$. Show that $\mu(F) = 0$ if and only if (2.4.2) holds.]

\begin{solution}
  Define
  \begin{equation*}
    F = \bigcup_{k=1}^\infty \varlimsup_n E_n \left( \frac{1}{k} \right) = \bigcup_{k=1}^\infty \bigcap_{n=1}^\infty \bigcup_{m=n}^\infty E_m \left( \frac{1}{k} \right).
  \end{equation*}
  Note that
  \begin{equation*}
    \begin{split}
      x \in F &\iff \exists k, \forall n, \exists m \ge n, \, |f_m(x) - f(x)| \ge \frac{1}{k} \\
      &\iff \neg \left( \forall k, \exists n, \forall m \ge n, \, |f_m(x) - f(x)| < \frac{1}{k} \right) \\
      &\iff f_n(x) \not\to f(x),
    \end{split}
  \end{equation*}
  so that
  \begin{equation*}
    F = \{x; \, f_n(x) \not\to f(x)\}.
  \end{equation*}

  Suppose (2.4.2) holds. Fix $\delta > 0$. For every positive integer $k$, there exists a positive integer $n_k$ such that $n \ge n_k$ implies
  \begin{equation*}
    \mu \left[ \bigcup_{m=n}^\infty E_m \left( \frac{1}{k} \right) \right] < \frac{\delta}{2^k}.
  \end{equation*}
  By subadditivity and monotonicity,
  \begin{equation*}
    \begin{split}
      \mu(F) &= \mu \left[ \bigcup_{k=1}^\infty \bigcap_{n=1}^\infty \bigcup_{m=n}^\infty E_m \left( \frac{1}{k} \right) \right] \le \sum_{k=1}^\infty \mu \left[ \bigcap_{n=1}^\infty \bigcup_{m=n}^\infty E_m \left( \frac{1}{k} \right) \right] \\
      &\le \sum_{k=1}^\infty \mu \left[ \bigcup_{m=n_k}^\infty E_m \left( \frac{1}{k} \right) \right] < \sum_{k=1}^\infty \frac{\delta}{2^k} = \delta.
    \end{split}
  \end{equation*}
  Since $\delta$ was arbitrary, $\mu(F) = 0$, and it follows that $f_n \to f$ a.e.

  Conversely, suppose $f_n \to f$ a.e., so that $\mu(F) = 0$. By monotonicity and Theorem 1.2.2,
  \begin{equation*}
    0 = \mu(F) = \mu \left[ \bigcup_{k=1}^\infty \varlimsup_n E_n \left( \frac{1}{k} \right) \right] \ge \mu \left[ \varlimsup_n E_n \left( \frac{1}{l} \right) \right] \ge \varlimsup_n \mu \left[ E_n \left( \frac{1}{l} \right) \right]
  \end{equation*}
  for all positive integers $l$. But of course $\varlimsup_n \mu \left[ E_n \left( 1/l \right) \right] \ge \varliminf_n \mu \left[ E_n \left( 1/l \right) \right] \ge 0$ since $\mu$ is nonnegative, so $\lim_n \mu \left[ E_n \left( 1/l \right) \right]$ exists and is equal to zero. Note that the sets $\bigcup_{m=n}^\infty E_m(1/l)$ are decreasing, so their limit as $n \to \infty$ exists. Hence we can apply Corollary 1.2.3 and monotonicity to find that
  \begin{equation*}
    \begin{split}
      \lim_n \mu \left[ \bigcup_{m=n}^\infty E_m \left( \frac{1}{l} \right) \right] &= \mu \left[ \lim_n \bigcup_{m=n}^\infty E_m \left( \frac{1}{l} \right) \right] = \mu \left[ \bigcap_{n=1}^\infty \bigcup_{m=n}^\infty E_m \left( \frac{1}{l} \right) \right] \\
      &\le \mu \left[\bigcup_{k=1}^\infty \bigcap_{n=1}^\infty \bigcup_{m=n}^\infty E_m \left( \frac{1}{k} \right) \right] = \mu(F) = 0.
    \end{split}
  \end{equation*}
  Finally, given $\epsilon > 0$, note that
  \begin{equation*}
    E_n(\epsilon) \subset E_n \left( \frac{1}{\lceil 1/\epsilon \rceil} \right).
  \end{equation*}
  Hence
  \begin{equation*}
    \lim_n \mu \left[ \bigcup_{m=n}^\infty E_m(\epsilon) \right] \le \lim_n \mu \left[ \bigcup_{m=n}^\infty E_m \left( \frac{1}{\lceil 1/\epsilon \rceil} \right) \right] \le 0
  \end{equation*}
  by monotonicity, and (2.4.2) follows.
\end{solution}

\subsubsection*{2.4.4}
Let $X$ be the set of all positive integers, $\cal A$ the class of all subsets of $X$, and $\mu(E)$ (for any $E \in \cal A$) the number of points in $E$. Prove that in this measure space, convergence in measure is equivalent to uniform convergence.

\begin{solution}
  Uniform convergence always implies convergence in measure. Conversely, suppose $(f_n)$ converges in measure to $f$. Given any $\epsilon > 0$, there exists a positive integer $N$ such that $n \ge N$ implies
  \begin{equation*}
    \mu \left[ \{x; \, |f_n(x) - f(x)| \ge \epsilon\} \right] < 1.
  \end{equation*}
  That is, for $n \ge N$ the set $\{x; \, |f_n(x) - f(x)| \ge \epsilon\}$ is empty, which in particular means that $\sup_x |f_n(x) - f(x)| \le \epsilon$. It follows that $f_n \to f$ uniformly.
\end{solution}

\section*{Section 2.5 -- Integrals of Simple Functions}

\subsection*{Problems}

\subsubsection*{2.5.2}
An integrable simple function $f$ is equal a.e.\ to zero if and only if $\int_E f d\mu = 0$ for any measurable set $E$.

\begin{solution}
  Let $f$ be an integrable simple function. Then $f$ can be written in the form
  \begin{equation*}
    f = \sum_{i=1}^n \alpha_i \chi_{E_i},
  \end{equation*}
  for mutually disjoint sets $E_1, \dots E_n$, with all $\alpha_i \ne 0$, and all $\mu(E_i) < \infty$.

  Suppose $f = 0$ a.e., and let $E$ be any measurable set. By Theorem 2.5.1(b) and (g),
  \begin{equation*}
    0 \le \int_E f d\mu \le \int f d\mu = \sum_{i=1}^n \alpha_i \mu(E_i).
  \end{equation*}
  But $\mu(E_i) = 0$ since $f = 0$ a.e., so $\int_E f d\mu = 0$.

  Conversely, suppose $\int_E f d\mu = 0$ for all measurable sets $E$. Then
  \begin{equation*}
    \alpha_i \mu(E_i) = \int_{E_i} f d\mu = 0,
  \end{equation*}
  so that $\mu(E_i) = 0$, for all $i \in \{1,\dots,n\}$. It follows that $f = 0$ a.e.
\end{solution}

\section*{Section 2.6 -- Definition of the Integral}

\subsection*{Problems}

\subsubsection*{2.6.3}
Let $f$ be a measurable function. Prove that $f$ is integrable if and only if $f^+$ and $f^-$ are integrable, or if and only if $|f|$ is integrable.

\begin{solution}
  Let $f$ be measurable. We must prove the equivalence of the following statements:
  \begin{enumerate}[label=(\roman*)]
    \item $f$ is integrable.
    \item $f^+$ and $f^-$ are integrable.
    \item $|f|$ is integrable.
  \end{enumerate}
  We will first show that (iii)$\implies$(ii), then that (ii)$\implies$(i), and finally that (i)$\implies$(iii).

  Suppose that $|f|$ is integrable. Let $E = \{x; \, f(x) \ge 0\} = f^{-1}{[0,\infty)}$, and note that $E$ is measurable since $f$ is. There exists a Cauchy in the mean sequence $(g_n)$ of integrable simple functions converging to $|f|$ a.e., and the sequence $(\chi_E g_n)$ is easily seen to satisfy the corresponding properties with respect to $f^+$. Since $f^+$ is measurable by Problem 2.1.8, this implies that it is integrable. The proof that $f^-$ is integrable is similar.

  Next, suppose that $f^+$ and $f^-$ are integrable. Then there exist Cauchy in the mean sequences $(g_n)$ and $(h_n)$ of integrable simple functions converging a.e.\ to $f^+$ and $f^-$, respectively. Define a new sequence $(f_n)$ of integrable simple functions by $f_n = g_n - h_n$. Then $(f_n)$ is Cachy in the mean, since
  \begin{equation*}
    |f_n - f_m| = |g_n - h_n - g_m + h_m| \le |g_n - g_m| + |h_n - h_m|.
  \end{equation*}
  It also converges to $f$ a.e.\, since
  \begin{equation*}
    |f_n - f| = |g_n - h_n - f^+ + f^-| \le |g_n - f^+| + |h_n - f^-|.
  \end{equation*}
  It follows that $f$ is integrable.

  Finally, assume that $f$ is integrable. There is a Cauchy in the mean sequence $(f_n)$ of integrable simple functions converging to $f$ a.e. The sequence $(|f_n|)$ consists of integrable simple functions. It is Cauchy in the mean since
  \begin{equation*}
    ||f_n| - |f_m|| \le |f_n - f_m|,
  \end{equation*}
  and it converges to $|f|$ a.e.\ since
  \begin{equation*}
    ||f_n| - |f|| \le |f_n - f|.
  \end{equation*}
  Since $|f|$ is measurable by Problem 2.1.9, it follows that $|f|$ is integrable.
\end{solution}

\subsubsection*{2.6.4}
Let $X$ be the measure space described in Problem 2.4.4. Then $f$ is integrable if and only if the series $\sum_{n=1}^\infty |f(n)|$ is convergent. If $f$ is integrable, then
\begin{equation*}
  \int f \, d\mu = \sum_{n=1}^\infty f(n).
\end{equation*}

\begin{solution}
  Suppose $f$ is integrable. Then there is a Cauchy in the mean sequence $(f_n)$ of integrable simple functions converging to $f$ a.e. We saw in the previous problem that this implies that $|f|$ is integrable, and that $(|f_n|)$ is a Cauchy in the mean sequence of integrable simple functions converging to $|f|$ a.e. Note that in this particular space convergence a.e.\ is the same as convergence everywhere (since the only subset with measure zero is $\emptyset$).

  By Theorem 2.5.1(h),
  \begin{equation*}
    \int |f_n| \, d\mu = \sum_{i=1}^\infty \int_{\{i\}} |f_n| \, d\mu = \sum_{i=1}^\infty |f_n(i)|.
  \end{equation*}
  Hence, in particular,
  \begin{equation*}
    \int |f| \, d\mu = \lim_{n \to \infty} \sum_{i=1}^\infty |f_n(i)|.
  \end{equation*}

  Given any positive integer $m$, there exists $n'$ such that
  \begin{equation*}
    {|f(i) - f_{n'}(i)|} < 1/m \quad (i = 1, 2, \dots, m)
  \end{equation*}
  (since $f_n \to f$) and
  \begin{equation*}
    \left| \sum_{i=1}^\infty |f_{n'}(i)| - \int |f| \, d\mu \right| < 1
  \end{equation*}
  (since $\sum_i |f_n(i)| \to \int |f| \, d\mu$). Thus
  \begin{equation*}
    \sum_{i=1}^m |f(i)| \le \sum_{i=1}^m |f(i) - f_{n'}(i)| + \sum_{i=1}^m |f_{n'}(i)| < 1 + \sum_{i=1}^\infty |f_{n'}(i)| < 2 + \int |f| \, d\mu,
  \end{equation*}
  and it follows that the series $\sum_{i=1}^\infty |f(i)|$ converges (to a finite number).

  Conversely, assume that the series $\sum_{i=1}^\infty |f(i)|$ converges. Define a sequence of integrable simple functions $(g_n)$ by
  \begin{equation*}
    g_n = \sum_{i=1}^n f(i) \chi_{\{i\}}.
  \end{equation*}
  It is clear that $g_n \to f$ everywhere. Moreover, if $m > n$, then
  \begin{equation*}
    \int |g_m - g_n| \, d\mu = \int \left| \sum_{i=n+1}^m f(i) \chi_{\{i\}} \right| d\mu = \sum_{n+1}^m |f(i)| \le \sum_{n+1}^\infty |f(i)|.
  \end{equation*}
  The right-hand side goes to zero as $n \to \infty$ since $\sum_{i=1}^\infty |f(i)|$ is convergent, which means that $\int |g_m - g_n| \, d\mu \to 0$ as $n,m \to \infty$; i.e., $(g_n)$ is Cauchy in the mean. It follows that $f$ is integrable, with
  \begin{equation*}
    \int f \, d\mu = \lim_{n \to \infty} \int g_n \, d\mu = \lim_{n \to \infty} \sum_{i=1}^n f(i) = \sum_{i=1}^\infty f(i).
  \end{equation*}
\end{solution}



\section*{Section 2.7 -- Elementary Properties of Integrals}

\subsection*{Problems}

\subsubsection*{2.7.3}
Let $f$ be an integrable function. Prove: (a) if $\int_E f d\mu \ge 0$ for all measurable sets $E$, then $f \ge 0$ a.e.; (b) if $\mu(X) < \infty$ and if $\int_E f d\mu \le \mu(E)$ for all measurable sets $E$, then $f \le 1$ a.e.

\begin{solution}
  \leavevmode
  \begin{enumerate}[label=(\alph*)]
    \item Let $F = \{x; \, f(x) < 0\}$. Then $-f$ is positive on $F$, so
      \begin{equation*}
        -\int_F f d\mu = \int_F (-f) d\mu \ge 0
      \end{equation*}
      by Theorem 2.7.1(b). But
      \begin{equation*}
        \int_F f d\mu \ge 0
      \end{equation*}
      by our hypothesis on $f$, so
      \begin{equation*}
        \int_F f d\mu = 0,
      \end{equation*}
      and it follows by Theorem 2.7.5 that $\mu(F) = 0$. That is, $f \ge 0$ a.e.

    \item Let $G = \{x: \, f(x) > 1\}$. Then $f-1$ is positive on $G$, so
      \begin{equation*}
        \int_G (f-1) d\mu \ge 0
      \end{equation*}
      by Theorem 2.7.1(b). Note that $\chi_G$ is integrable since $\mu(G) \le \mu(X) < \infty$. Hence we also have
      \begin{equation*}
        \int_G (f-1) d\mu = \int_G f d\mu - \int_G d\mu = \int_G f d\mu - \mu(G) \le 0,
      \end{equation*}
      with the inequality following from our hypothesis on $f$. Thus
      \begin{equation*}
        \int_G (f-1) d\mu = 0,
      \end{equation*}
      and Theorem 2.7.5 yields $\mu(G) = 0$. That is, $f \le 1$ a.e.
  \end{enumerate}
\end{solution}

\section*{Section 2.8 -- Sequences of Integrable Functions}

\subsection*{Problems}

\subsubsection*{2.8.1}
A measurable function $f$ is acalled a \emph{null function} if $f = 0$ a.e. We shall say that $f$ is \emph{equivalent} to $g$ (and write $f \sim g$) if $f - g$ is a null function. Denote by $\bar f$ the class of all measurable functions that are equivalent to $f$. We denote by $L^1(X, \cal A, \mu)$, or, more briefly, by $L^1(X,\mu)$, the set of all classes $\bar f$ for which $f$ is integrable, and define on it the function
\begin{equation*}
  \rho(\bar f, \bar g) = \rho(f, g) = \int |f-g| d\mu.
\end{equation*}
[Note that if $f_0 \in \bar f$, $g_0 \in \bar g$, then $\rho(f_0,g_0) = \rho(f,g)$.] Prove that $L^1(X,\mu)$ is a complete metric space with the metric $\rho$.

\begin{solution}
  Let $(\bar f_n)$ be a Cauchy sequence in $L^1(X,\mu)$. Then
  \begin{equation*}
    \int |f_m - f_n| d\mu = \rho(\bar f_m, \bar f_n) \to 0
  \end{equation*}
  as $m,n \to \infty$, so the sequence $(f_n)$ (of representative functions) is Cauchy in the mean. By Theorem 2.8.3 there is an integrable function $f$ such that $f_n \to f$ in the mean. Hence
  \begin{equation*}
    \rho(\bar f_n, \bar f) = \int |f_n - f| d\mu \to 0
  \end{equation*}
  as $n \to \infty$. That is, $\bar f_n \to \bar f$ in $L^1(X,\mu)$.
\end{solution}

\subsection*{2.8.2}
TODO.


\section*{Section 2.9 -- Lebesgue's Bounded Convergence Theorem}

\subsection*{Problems}

\subsubsection*{2.9.1}
Let $f_n(x) = n$ if $0 \le x < 1/n$, $f_n(x) = 0$ if $1 \ge x \ge 1/n$. Then $\lim_n f_n(x) = 0$ on $[0,1]$, but $\lim_n \int f_n d\mu = 1$ ($\mu$ is the Lebesgue integral). This example shows that the boundedness condition $|f_n| \le g$ in Theorem 2.9.1 is essential.

\begin{solution}
  Indeed $f_n(x) \to 0$ for all $x > 0$, and
  \begin{equation*}
    \mu([0,1] - (0,1]) = \mu(\{0\}) = 0,
  \end{equation*}
  so $f_n(x) \to 0$ a.e. Note that $f_n = n \chi_{[0,1/n)}$ for each $n$, so that
  \begin{equation*}
    \int f_n d\mu = n \mu([0,1/n)) = n \frac{1}{n} = 1.
  \end{equation*}
  Hence $\lim_n \int f_n d\mu = 1$.
\end{solution}

\subsubsection*{2.9.4}
If $\mu(X) < \infty$ and if $\{f_n\}$ is a sequence of measurable functions that converges uniformly to a function $f$, then $f$ is integrable and $\lim_n \int f_n d\mu = \int f d\mu$.

\begin{solution}
  The problem statement, as written, is wrong. For a counterexample, let $X = \{1,2, \dots\}$ and define the measure by $\mu(\{x\}) = 2^{-x}$ (extended additively to all subsets of $X$). Then $\mu(X) = 1$. Define $f$ by $f(x) = 2^x$ and let $f_n = f$ for all $n$. These definitions match the assumptions of the problem, but
  \begin{equation*}
    f \ge g_n := \sum_{i=1}^n f(i) \chi_{\{i\}}
  \end{equation*}
  for all $n$, and
  \begin{equation*}
    \int g_n d\mu = n \to \infty,
  \end{equation*}
  so $f$ cannot possibly be integrable.

  We will therefore assume that the functions $f_n$ are integrable, not just measurable. Given any $\epsilon > 0$, there is an integer $N$ such that $n \ge N$ implies $|f_n - f| < \epsilon$. Hence
  \begin{equation*}
    |f_m - f_n| \le |f_m - f| + |f_n - f| < 2 \epsilon
  \end{equation*}
  whenever $m,n \ge N$, and
  \begin{equation*}
    \int |f_m - f_n| d\mu \le 2 \epsilon \mu(X).
  \end{equation*}
  It follows (since $\mu(X) < \infty$) that the sequence $(f_n)$ is Cauchy in the mean, hence that $f$ is integrable and $\int f d\mu = \lim_n \int f_n d\mu$ by Theorem 2.8.2

  Remark: Assuming that the functions $f_n$ are integrable might not be the right way to fix to this problem, in particular since we did not even need to use the bounded convergence theorem to solve this version of it.

\end{solution}


\section*{Section 2.10 -- Applications of Lebesgue's \\ Bounded Convergence Theorem}

\subsection*{Problems}

\subsubsection*{2.10.2}
Derive the Lebesgue monotone convergence theorem from Fatou's Lemma.

\begin{solution}
  Let $(f_n)$ be a monotone increasing sequence of non-negative integrable functions. Note that
  \begin{equation*}
    \varliminf_n f_n(x) = \lim_n \inf_{j \ge n} f_j(x) = \lim_n f_n(x)
  \end{equation*}
  for all $x$, since $f_1(x) \le f_2(x) \le \dotsm$. Similarly,
  \begin{equation*}
    \varliminf_n \int f_n d\mu = \lim_n \int f_n d\mu.
  \end{equation*}
  By Fatou's lemma (Theorem 2.10.5),
  \begin{equation*}
    \int \lim_n f_n d\mu = \int \varliminf_n f_n d\mu \le \varliminf_n \int f_n d\mu = \lim_n \int f_n d\mu.
  \end{equation*}
  (Note that either the right-hand side or both sides of this inequality may be infinite.) On the other hand we also have
  \begin{equation*}
    \lim_n \int f_n d\mu \le \int \lim_n f_n d\mu
  \end{equation*}
  (again with the possibility of infinite values), since $f_j \le \lim_n f_n$ for all $j$. Combining these results, we obtain
  \begin{equation*}
    \lim_n \int f_n d\mu = \int \lim_n f_n d\mu,
  \end{equation*}
  with both sides either finite or infinite.
\end{solution}

\subsubsection*{2.10.7}
Let $\{f_n\}$ be a sequence of integrable functions. Prove that if $\sum_{n=1}^\infty \int |f_n| d\mu < \infty$, then the series $\sum_{n=1}^\infty f_n(x)$ is convergent to an integrable function $f(x)$, and
\begin{equation*}
  \int f \, d\mu = \sum_{n=1}^\infty \int f_n d\mu.
\end{equation*}

\begin{solution}
  Assume that
  \begin{equation*}
    \sum_{n=1}^\infty \int |f_n| \, d\mu < \infty.
  \end{equation*}
  For each $n \ge 1$, let
  \begin{equation*}
    g_n = \sum_{i=1}^n f_i^+.
  \end{equation*}
  Then $(g_n)$ is a monotone-increasing sequence of nonnegative integrable functions. Also define $g = \lim_n g_n$. By the monotone convergence theorem (Theorem 2.10.4),
  \begin{equation*}
    \int g \, d\mu = \lim_n \int g_n d\mu = \lim_n \int \sum_{i=1}^n f_i^+ d\mu = \lim_n \sum_{i=1}^n \int f_i^+ d\mu = \sum_{n=1}^\infty \int f_n^+ d\mu,
  \end{equation*}
  which is finite, since
  \begin{equation*}
    \sum_{n=1}^\infty \int f_n^+ d\mu \le \sum_{n=1}^\infty \int |f_n| \, d\mu < \infty.
  \end{equation*}
  Similarly defining $h_n = \sum_{i=1}^n f_i^-$ and $h = \lim_n h_n$, we find that 
  \begin{equation*}
    \int h \, d\mu = \sum_{n=1}^\infty \int f_i^- d\mu < \infty.
  \end{equation*}
  
  Next, define $f = g - h$. Note that $f$ is integrable by the above, and that
  \begin{equation*}
    f = \sum_{n=1}^\infty (f_n^+ - f_n^-) = \sum_{n=1}^\infty f_n.
  \end{equation*}
  Also by what we found above,
  \begin{equation*}
    \int f \, d\mu = \int g \, d\mu - \int h \, d\mu = \sum_{n=1}^\infty \int f_n^+ d\mu - \sum_{n=1}^\infty \int f_n^- d\mu,
  \end{equation*}
  from which we easily get
  \begin{equation*}
    \int f \, d\mu = \sum_{n=1}^\infty \int f_n d\mu.
  \end{equation*}
\end{solution}

\subsubsection*{2.10.8}
Let $\{f_n\}$ be a sequence of nonnegative integrable functions. Prove that if the series $f(x) = \sum f_n(x)$ is an integrable function, then $\sum_{n=1}^\infty \int f_n d\mu < \infty$.

\begin{solution}
  Assume that $f$ is integrable. Then
  \begin{equation*}
    \sum_{n=1}^m \int f_n d\mu = \int \sum_{n=1}^m f_n d\mu \le \int f \, d\mu < \infty
  \end{equation*}
  for every $m$. Also,
  \begin{equation*}
    \sum_{n=1}^m \int f_n d\mu \le \sum_{n=1}^{m+1} \int f_n d\mu
  \end{equation*}
  for every $m$, since the functions $f_n$ are nonnegative. Hence the partial sums make up a monotone-increasing sequence of real numbers that is bounded above, and it follows that they converge to a finite number.
\end{solution}

\subsubsection*{2.10.9}
Let $f$ and $f_n$ ($n = 1,2,\dots$) be integrable functions such that $0 \le f_n(x) \le f(x)$ a.e. Then
\begin{equation*}
  \int \left( \varlimsup_n f_n \right) d\mu \ge \varlimsup_n \int f_n d\mu \ge \varliminf_n \int f_n d\mu \ge \int \left( \varliminf_n f_n \right) d\mu.
\end{equation*}

\begin{solution}
  For each $n \ge 1$, define
  \begin{equation*}
    E_n = \{x; \, 0 \le f_n(x) \le f(x)\},
  \end{equation*}
  and let $N = \bigcup_n E_n^c$. Each set $E_n^c$ has measure zero by the given assumptions on $f_n$ and $f$, hence so does $N$. Define new functions $\tilde f_n$ and $\tilde f$ which are identical to $f_n$ and $f$ except that they vanish on $N$. Then $\tilde f_n(x) = f_n(x)$ a.e., $\tilde f(x) = f(x)$ a.e., and $0 \le \tilde f_n(x) \le \tilde f(x)$ \emph{everywhere}. The new functions are integrable by Problem 2.6.1, and their integrals are identical to the old ones. Similarly, $\varliminf_n \tilde f_n(x) = \varliminf_n f_n(x)$ a.e. and $\varlimsup_n \tilde f_n(x) = \varlimsup_n f_n(x)$ a.e., once again with integrals unchanged (integrability follows from Theorem 2.10.1, with $f$ or $\tilde f$ bounding from above). Thus we can safely assume that $0 \le f_n(x) \le f(x)$ holds everywhere; otherwise we simply work with the functions $\tilde f_n$ and $\tilde f$ instead.

  With such an assumption the inequality
  \begin{equation*}
    \int \varliminf_n f_n d\mu \le \varliminf_n \int f_n d\mu
  \end{equation*}
  follows immediately from Fatou's lemma. The next inequality,
  \begin{equation*}
    \varliminf_n \int f_n d\mu \le \varlimsup_n \int f_n d\mu,
  \end{equation*}
  is trivial. For the final inequality, note that
  \begin{equation*}
    f(x) - \varlimsup_n f_n(x) = \varliminf_n (f(x) - f_n(x))
  \end{equation*}
  for all $x$. Hence, again by Fatou's lemma,
  \begin{equation*}
    \begin{split}
      \int f \, d\mu - \int \varlimsup_n f_n d\mu &= \int \varliminf_n (f - f_n) d\mu \\
      &\le \varliminf_n \int (f - f_n) d\mu \\
      &= \varliminf_n \left( \int f \, d\mu - \int f_n d\mu \right) \\
      &= \int f \, d\mu - \varlimsup_n \int f_n d\mu,
    \end{split}
  \end{equation*}
  whereby
  \begin{equation*}
    \varlimsup_n \int f_n d\mu \le \int \varlimsup_n f_n d\mu.
  \end{equation*}
\end{solution}

\subsubsection*{2.10.11}
Let $X = \bigcup_{n=1}^\infty E_n$, $E_n \subset E_{n+1}$ for all $n$. Let $f$ be a nonnegative measurable function. Prove that
\begin{equation*}
  \int f \, d\mu = \lim_{n \to \infty} \int_{E_n} f \, d\mu.
\end{equation*}

\begin{solution}
  Note that $(\chi_{E_n} f)$ is a monotone-increasing sequence of nonnegative measurable functions, and that
  \begin{equation*}
    \int_{E_n} f \, d\mu = \int \chi_{E_n} f \, d\mu.
  \end{equation*}
  Consider first the case that there is some $n$ such that $\chi_{E_n} f$ is not integrable. Then $f$ cannot be integrable, and $\chi_{E_m} f$ cannot be integrable for $m \ge n$, by Theorem 2.10.1 (since these functions bound $\chi_{E_n} f$ from above). Hence
  \begin{equation*}
    \int f \, d\mu = \lim_n \int \chi_{E_n} f \, d\mu = \infty
  \end{equation*}
  in this case. If on the other hand all of the functions $\chi_{E_n} f$ are integrable, then the monotone convergence theorem tells us that
  \begin{equation*}
    \lim_n \int \chi_{E_n} f \, d\mu = \int f \, d\mu,
  \end{equation*}
  since $ \lim_n \chi_{E_n} f = f$.
\end{solution}

\subsubsection*{2.10.12}
Let $f$ be a nonnegative measurable function and let
\begin{equation*}
  f_n(x) =
  \begin{cases}
    f(x), & \text{if $f(x) \le n$,} \\
    n, & \text{if $f(x) > n$.}
  \end{cases}
\end{equation*}
Prove that $\lim_n \int f_n d\mu = \int f d\mu$.

\begin{solution}
  Note that $(f_n)$ is a monotone-increasing sequence of nonnegative measurable functions, with $\lim_n f_n = f$. If $f_n$ is not integrable for some $n$, then
  \begin{equation*}
    \int f \, d\mu = \lim_n \int f_n d\mu = \infty
  \end{equation*}
  by Theorem 2.10.1. Otherwise the result follows by the monotone convergence theorem.
\end{solution}

\subsubsection*{2.10.14}
Give an example where Fatou's lemma holds with strict inequality.

\begin{solution}
  Consider $[0,1] \subset \bb R$ with Lebesgue measure. Let $f_n = \chi_{[0,1/2]}$ for odd $n$, and $f_n = \chi_{(1/2,1]}$ for even $n$. Then
  \begin{equation*}
    \int f_n d\mu = \frac{1}{2}
  \end{equation*}
  for all $n$, so that
  \begin{equation*}
    \varliminf_n \int f_n d\mu = \frac{1}{2},
  \end{equation*}
  but $\varliminf_n f_n = 0$ so that
  \begin{equation*}
    \int \varliminf_n f_n d\mu = 0.
  \end{equation*}
\end{solution}

\chapter*{Chapter 3 -- Metric Spaces}

\section*{Section 3.1 -- Topological and Metric Spaces}

\subsection*{Problems}

\subsubsection*{3.1.1}
Prove that if $(X,p)$ is a metric space, and if
\begin{equation*}
  \hat \rho(x,y) = \frac{\rho(x,y)}{1 + \rho(x,y)},
\end{equation*}
then also $(X,\hat \rho)$ is a metric space. [\emph{Hint:} Cf.\ the proof of (3.1.3).]

\begin{solution}
  The only nonobvious property is the triangle inequality. Let $x,y,z$ be arbitrary points of $X$. Since $t \mapsto t/(1+t)$ is monotone increasing on $[0,\infty)$, and since $\rho(x,z) \le \rho(x,y) + \rho(y,z)$, we have
  \begin{equation*}
    \frac{\rho(x,z)}{1 + \rho(x,z)} \le \frac{\rho(x,y) + \rho(y,z)}{1 + \rho(x,y) + \rho(y,z)}.
  \end{equation*}
  Moreover, by equation (3.1.3),
  \begin{equation*}
    \frac{\rho(x,y) + \rho(y,z)}{1 + \rho(x,y) + \rho(y,z)} \le \frac{\rho(x,y)}{1 + \rho(x,y)} + \frac{\rho(y,z)}{1 + \rho(y,z)}.
  \end{equation*}
  It follows that $\hat \rho(x,z) \le \hat \rho(x,y) + \rho(y,z)$.
\end{solution}

\subsubsection*{3.1.2}
Let $X, \rho, \hat \rho$ be as in Problem 3.1.1. Prove that $\rho(x_n, x) \to 0$ if and only if $\hat \rho(x_n, x) \to 0$. Give an example showing that $\rho$ and $\hat \rho$ are not equivalent in general.

\begin{solution}
  It is clear that $\rho(x_n, x) \to 0$ implies $\hat \rho (x_n, x) \to 0$, since $\hat \rho \le \rho$.
  
  Conversely, suppose $\hat \rho(x_n, x) \to 0$. Given any $\epsilon > 0$, there is a positive integer $N$ such that
  \begin{equation*}
    \hat \rho(x_n, x) < \frac{\epsilon}{1 + \epsilon} \quad (n \ge N).
  \end{equation*}
  Substituting the definition of $\hat \rho$ and rearranging yields $\rho(x_n, x) < \epsilon$.

  If $\rho$ and $\hat \rho$ are equivalent then, in particular, there exists a positive constant $\beta$ such that
  \begin{equation*}
    \frac{\rho(x,y)}{\hat \rho(x,y)} \le \beta
  \end{equation*}
  whenever $x \ne y$. But
  \begin{equation*}
    \frac{\rho(x,y)}{\hat \rho(x,y)} = 1 + \rho(x,y),
  \end{equation*}
  so this is impossible if $X$ is unbounded (w.r.t.\ $\rho$), say if $X = \bb R^n$ and $\rho$ is the Euclidean metric.
\end{solution}

\subsubsection*{3.1.6}
Prove that the spaces $l^1, s, c, c_0$ are separable metric spaces.

\begin{solution}
  For each of the spaces $X$ we will take an arbitrary element $x \in X$ and demonstrate that every $\epsilon$-ball around $x$ contains a point $y$ of a certain countable subset $Y \subset X$. It will then follow that $Y$ is dense in $X$, and hence that $X$ is separable.

  Let $x = (x_i) \in l^1$. Fix $\epsilon > 0$. Since $\sum_i |x_i| < \infty$, there exists $n$ such that
  \begin{equation*}
    \sum_{i=n+1}^\infty |x_i| < \frac{\epsilon}{2}.
  \end{equation*}
  For $i = 1, \dots, n$, choose $y_i \in \bb Q$ (or $y_i$ with rational real and imaginary parts in the complex case) such that $|x_i - y_i| < \epsilon/2n$, and let $y = (y_1, \dots, y_n, 0, 0, \dots)$. Then
  \begin{equation*}
    \rho(x,y) = \sum_{i=1}^n |x_i - y_i| + \sum_{i=n+1}^\infty |x_i| < \epsilon.
  \end{equation*}
  Moreover, $y$ is an element of the subset of $l^1$ consisting of sequences with rational components, with only finitely many being nonzero. This subset is easily seen to be countable, and it follows that $l^1$ is separable.

  Next, let $x = (x_i) \in s$, and fix $\epsilon > 0$. Choose $n$ such that
  \begin{equation*}
    \sum_{i=n+1}^\infty \frac{1}{2^i} \frac{|x_i|}{1 + |x_i|} < \frac{\epsilon}{2}.
  \end{equation*}
  For $i = 1, \dots, n$, choose $y_i \in \bb Q$ such that $|x_i - y_i| < \epsilon/2$, and let $y = (y_1, \dots, y_n, 0, 0, \dots)$. Then
  \begin{equation*}
    \rho(x,y) = \sum_{i=1}^n \frac{1}{2^i} \frac{|x_i - y_i|}{1 + |x_i - y_i|} + \sum_{i=n+1}^\infty \frac{1}{2^i} \frac{|x_i|}{1 + |x_i|} < \epsilon.
  \end{equation*}
  Similarly to the above, it follows that $s$ is dense.

  Finally, let $x = (x_i) \in c$. (This argument will also cover $c_0$.) Let $\xi = \lim_i x_i$ and fix $\epsilon > 0$. Choose $n$ such that $|x_i - \xi| < \epsilon/2$ for all $i \ge n$. For $i = 1, \dots, n-1$, choose $y_i \in \bb Q$ such that $|x_i - y_i| < \epsilon$. Also choose $\eta \in \bb Q$ such that $|\xi - \eta| < \epsilon/2$ (take $\eta = \xi = 0$ in the $c_0$ case), so that
  \begin{equation*}
    |x_i - \eta| \le |x_i - \xi| + |\xi - \eta| < \epsilon
  \end{equation*}
  for all $i \ge n$. Let $y = (y_1, \dots, y_{n-1}, \eta, \eta, \dots)$. Then
  \begin{equation*}
    \rho(x,y) = \sup_i |x_i - y_i| \le \epsilon.
  \end{equation*}
  It follows that $c$ is separable (and $c_0$ as well).
\end{solution}

\subsubsection*{3.1.10}
If $\rho(x_n, x) \to 0$, $\rho(y_n, y) \to 0$, then $\rho(x_n, y_n) \to \rho(x,y)$.

\begin{solution}
  The triangle inequality yields
  \begin{equation*}
    \rho(x_n,y_n) \le \rho(x_n, x) + \rho(x, y) + \rho(y, y_n)
  \end{equation*}
  and
  \begin{equation*}
    \rho(x,y) \le \rho(x, x_n) + \rho(x_n, y_n) + \rho(y_n, y).
  \end{equation*}
  Hence
  \begin{equation*}
    |\rho(x_n, y_n) - \rho(x,y)| \le \rho(x_n, x) + \rho(y_n, y),
  \end{equation*}
  and the result follows.
\end{solution}

\section*{Section 3.2 -- $L^p$ Spaces}

\subsection*{Problems}

\subsubsection*{3.2.4}
Prove that $l^p$ is separable if $1 \le p < \infty$.

\begin{solution}
  The argument is of the same sort as in Problem 3.1.6. Given $x = (x_i) \in l^p$ ($1 \le p < \infty$) and $\epsilon > 0$, choose $n$ such that
  \begin{equation*}
    \sum_{i=n+1}^\infty |x_i|^p < \frac{\epsilon^p}{2}.
  \end{equation*}
  (This is possible since $\sum_i |x_i|^p < \infty$ for $x \in l^p$.) For $i = 1, \dots, n$, choose $y_i \in \bb Q$ such that $|x_i - y_i|^p < \epsilon^p / 2n$ and let $y = (y_1, \dots, y_n, 0, 0, \dots)$. Then $\norm{x-y}_p < \epsilon$, and the conclusion follows as in Problem 3.1.6.
\end{solution}

\subsubsection*{3.2.5}
Prove that $l^p$ is not a metric space if $0 < p < 1$.

\begin{solution}
  Let $x = (1,0,0,\dots)$, $y = (0,0,\dots)$, $z = (0,1,0,0,\dots)$. Then
  \begin{equation*}
    \norm{x-z}_p = 2^{1/p}
  \end{equation*}
  while
  \begin{equation*}
    \norm{x-y}_p + \norm{y-z}_p = 2.
  \end{equation*}
  But $2^{1/p} > 2$ if $0 < p < 1$, so the triangle inequality does not hold.
\end{solution}

\subsubsection*{3.2.6}
Prove that the space $C[a,b]$ with the metric
\begin{equation*}
  \rho(f,g) = \int_a^b |f(t) - g(t)| \, dt
\end{equation*}
is not a complete metric space.

\begin{solution}
  Note that the integral defining $\rho$ is guaranteed to exist by Theorem 2.11.1 and the extreme value theorem from elementary analysis, and it can be taken in the Riemann sense. It is easily seen that $\rho$ is indeed a metric. 

  For simplicity, let us assume $a = 0$ and $b = 1$. (The general argument is identical modulo a coordinate transformation.) Define a sequence of functions in $C[0,1]$ by $f_n(x) = x^n$. Clearly $(f_n)$ converges pointwise to the discontinuous function
  \begin{equation*}
    f(x) =
    \begin{cases}
      0 & (0 \le x < 1), \\
      1 & (x = 1).
    \end{cases}
  \end{equation*}
  For $n \le m$ we have $f_n \ge g_n$, hence
  \begin{equation*}
    \rho(f_n, f_m) = \int_0^1 f_n(t) \, dt - \int_0^1 f_m(t) \, dt = \frac{1}{n+1} - \frac{1}{m+1},
  \end{equation*}
  which goes to zero as $n,m \to \infty$. Thus $(f_n)$ is a Cauchy sequence in $C[0,1]$ which converges to a function $f$ which is not in $C[0,1]$, so $(C[0,1], \rho)$ is not a complete metric space.
\end{solution}

\section*{Section 3.4 -- Complete Metric Spaces}

\subsection*{Problems}

\subsubsection*{3.4.5}
A set $Y$ in a metric space $X$ is said to be \emph{of the first category in $X$} if it is contained in a countable union of nowhere dense sets of $X$. If $Y$ is not of the first category in $X$, then it is said to be \emph{of the second category in $X$}. The real line with the Euclidean metric is a space of the second category. Prove, however, that, as a subset of the Euclidean plane, the real line is a set of the first category.

\begin{solution}
  We identify the real line with the subset $L = \{(x,y) \in \bb R^2: y = 0\}$, with the induced metric topology. Indeed $L$ is homeomorphic to $\bb R$ via the map $(x,0) \mapsto x$, as can easily be shown.

  The sets of the form $B((0,0), r) \cap L = \{(x,0): |x| < r\}$ are easily seen to be nowhere dense in $\bb R^2$, and we have
  \begin{equation*}
    L = \bigcup_{n=1}^\infty B((0,0), n) \cap L.
  \end{equation*}
  Hence $L$ is of the first category in $\bb R^2$.
\end{solution}

\subsubsection*{3.4.7}
Let $f(x)$ be a real-valued function on the real line. Prove that there is a nonempty interval $(a,b)$ and a positive number $c$ such that for any $x \in (a,b)$ there is a sequence $\{x_n\}$ such that $x_n \to x$ and $|f(x_n)| \le c$.

\begin{solution}
  Note that
  \begin{equation*}
    \bb R = |f|^{-1}(\bb R) = |f|^{-1} \left( \bigcup_{n=1}^\infty (-\infty,n] \right) = \bigcup_{n=1}^\infty |f|^{-1} \left( (-\infty,n] \right).
  \end{equation*}
  Since $\bb R$ is of the second category (by Theorem 3.4.2), the sets $|f|^{-1}((-\infty,n])$ cannot all be nowhere dense. Hence there is a positive integer $c$ such that the closure of $|f|^{-1}((-\infty,c])$ has nonempty interior. On account of being a nonempty open set, this interior contains an open interval $(a,b)$.

  Let $x \in (a,b)$. Then, since $x$ is contained in the closure of $|f|^{-1}((-\infty,c])$, every neighborhood of $x$ contains a point of $|f|^{-1}((-\infty,c])$. It follows that we can construct a sequence $(x_n)$ in $|f|^{-1}((-\infty,c])$ converging to $x$, and this sequence will satisfy $|f(x_n)| \le c$ for all $n$.
\end{solution}

\section*{Section 3.5 -- Compact Metric Spaces}

\subsection*{Problems}

\subsubsection*{3.5.4}
A subset $F$ of a compact metric space is compact if and only if it is closed.

\begin{solution}
  Let $X$ be a compact metric space, and $F$ a subset of $X$. If $F$ is compact then it is also closed by Corollary 3.5.5.

  Conversely, suppose that $F$ is closed. Let $\sc C$ be any open cover of $F$. The collection $\sc C \cup \{X - F\}$ is an open cover of $X$, hence it has a finite subcover, consisting of some sets $E_1, \dots, E_n \in \sc C$ and perhaps $\{X - F\}$. The sets $E_1, \dots, E_n$ cover $F$, hence $F$ is compact.
\end{solution}

\subsubsection*{3.5.5}
A subset $Y$ of a metric space is totally bounded if and only if its closure $\overline Y$ is totally bounded.

\begin{solution}
  Clearly $Y$ is totally bounded whenever $\overline Y$ is. Conversely, suppose $Y$ is totally bounded, and let $\epsilon > 0$ be given. Then $Y$ admits a finite $\epsilon/2$-covering,
  \begin{equation*}
    \{B(x_1, \epsilon/2), \dots, B(x_n, \epsilon/2)\}.
  \end{equation*}
  The union of the closed balls,
  \begin{equation*}
    \bigcup_{i=1}^n \overline B(x_i, \epsilon/2),
  \end{equation*}
  is a closed set containing $Y$, hence it contains $\overline Y$. It follows that
  \begin{equation*}
    \overline Y \subset \bigcup_{i=1}^n \overline B(x_i, \epsilon/2) \subset \bigcup_{i=1}^n B(x_i, \epsilon),
  \end{equation*}
  so $\overline Y$ admits a finite $\epsilon$-covering.
\end{solution}

\subsubsection*{3.5.6}
The intersection of any number of compact subsets of a metric space is a compact space.

\begin{solution}
  Let $\sc C$ be a collection of compact subsets of a metric space $X$. By Corollary 3.5.5 each $C \in \sc C$ is closed, hence the intersection $K = \bigcap \sc C$ is closed as well. Let $C'$ be some particular member of $\sc C$. Then $K$ is a closed subset of the compact space $C'$, thus itself compact by Problem 3.5.4.

  Remark: Really the above shows that $K$ is compact \emph{in $C'$}. However, one easily proves the general result that if $F$ is compact in $G$, and $G$ is compact in $H$, then $F$ is compact in $H$. Hence $K$ is indeed compact in $X$.
\end{solution}

\subsubsection{3.5.8}
Show that a metric space is compact if and only if it has the following property: for every collection of closed subsets $\{F_\alpha\}$, if any finite subcollection has nonempty intersection, then the whole collection has a nonempty intersection.

\begin{solution}
  The wording of the problem is potentially misleading. Replace ``any'' with ``every'' to make it nonambiguous. Also, let us introduce some useful terminology. A collection of subsets of a topological space is said to have the \emph{finite intersection property} iff every finite subcollection has nonempty intersection. Our task is therefore to show that a metric space $X$ is compact iff every collection $\sc F$ of closed subsets of $X$ having the finite intersection property has nonempty intersection. However, the proof we will use is valid for general topological spaces, not just metric spaces.

  Let $X$ be a topological space, and suppose first that $X$ is compact. Let $\sc F$ be a collection of closed subsets of $X$ with the finite intersection property. Assume towards a contradiction that $\bigcap \sc F = \emptyset$. Then
  \begin{equation*}
    \bigcup_{F \in \sc F} (X - F) = X - \bigcap_{F \in \sc F} F = X,
  \end{equation*}
  so $\{X - F; \, F \in \sc F\}$ is an open cover of $X$. Since $X$ is compact, there are sets $F_1, \dots, F_n \in \sc F$ such that
  \begin{equation*}
    X = \bigcup_{i=1}^n (X - F_i) = X - \bigcap_{i=1}^n F_i.
  \end{equation*}
  But then $\bigcap_{i=1}^n F_i = \emptyset$, contradicting the hypothesis that $\sc F$ has the finite intersection property. We conclude that $\bigcap \sc F \ne \emptyset$.

  Conversely, suppose that $X$ has the property described in the problem statement: every collection of closed subsets of $X$ with the finite intersection property has nonempty intersection. Let $\sc U$ be any open cover of $X$, and assume towards a contradiction that $\sc U$ has no finite subcover. Then
  \begin{equation*}
    \bigcap_{i=1}^n (X - U_i) = X - \bigcup_{i=1}^n U_i \ne \emptyset
  \end{equation*}
  for every finite subcollection $\{U_1, \dots, U_n\} \subset \sc U$. Hence $\sc F = \{X - U; \, U \in \sc U\}$ is a collection of closed subsets with the finite intersection property. By hypothesis $\sc F$ has nonempty intersection, so
  \begin{equation*}
    \emptyset = X - \bigcup_{U \in \sc U} U = \bigcap_{U \in \sc U} (X - U) = \bigcap_{F \in \sc F} F \ne \emptyset,
  \end{equation*}
  a contradiction. We conclude that $\sc U$ does indeed have a finite subcover, and that $X$ is compact.
\end{solution}


\chapter*{Chapter 4 -- Elements of Functional Analysis in Banach Spaces}

\section*{Section 4.1 -- Linear Normed Spaces}

\subsection*{Problems}

\subsubsection*{4.1.4}
If $\{x_n\}$ is a convergent sequence in a normed linear space, with limit $x$, then also the sequence with elements $(x_1 + \dots + x_n)/n$ is convergent to $x$.

\begin{solution}
  For $n=1,2,\dots$, define
  \begin{equation*}
    \sigma_n = \frac{x_1 + \dots + x_n}{n} = \frac{1}{n} \sum_{i=1}^n x_i.
  \end{equation*}
  Let $\epsilon > 0$ be given. Since $(x_n)$ is convergent there exists a positive integer $m$ such that $\norm{x_n - x} < \epsilon/2$ for all $n \ge m+1$. For such $n$ we have
  \begin{equation*}
    \begin{split}
      \norm{\sigma_n - x} &= \snorm{\frac{1}{n} \sum_{i=1}^n (x_i - x)} \\
      &\le \frac{1}{n} \snorm{\sum_{i=1}^m (x_i - x)} + \frac{1}{n} \snorm{\sum_{i=m+1}^n (x_i - x)} \\
      &\le \frac{1}{n} \snorm{\sum_{i=1}^m (x_i - x)} + \frac{1}{n} \sum_{i=m+1}^n \norm{x_i - x} \\
      &\le \frac{1}{n} \snorm{\sum_{i=1}^m (x_i - x)} + \frac{n-m-1}{n} \cdot \frac{\epsilon}{2}.
    \end{split}
  \end{equation*}
  The first term on the right-hand side goes to zero as $n \to \infty$, and the other goes to $\epsilon/2$. Hence $\norm{\sigma_n - x} < \epsilon$ for sufficiently large $n$, and it follows that $\sigma_n \to x$.
\end{solution}

\subsubsection*{4.1.6}
A normed linear space is a Banach space if the following property is satisfied: every absolutely convergent series is convergent.

\begin{solution}
  Let $X$ be a normed linear space with the property that every absolutely convergent series is convergent. Let $(x_n)$ be a Cauchy sequence in $X$, and choose integers $N_1 < N_2 < \dotsm$ such that $m,n \ge N_k$ implies $\norm{x_m - x_n} < 2^{-k}$. Define a new sequence $(y_k)$ by $y_1 = x_{N_1}$ and $y_k = x_{N_k} - x_{N_{k-1}}$ for $k > 1$. Then
  \begin{equation*}
    \sum_{k=1}^\infty \norm{y_k} = \norm{x_{N_1}} + \sum_{k=2}^\infty \norm{x_{N_k} - x_{N_{k-1}}} \le \norm{x_{N_1}} + \sum_{k=1}^\infty 2^{-k} = \norm{x_{N_1}} + 1.
  \end{equation*}
  It follows by our hypothesis on $X$ that
  \begin{equation*}
    x_{N_k} = \sum_{i=1}^k y_i
  \end{equation*}
  converges to some $x \in X$. Given $\epsilon > 0$, choose an integer $j \ge 1$ such that $2^{-j} < \epsilon$, and $k > j$ such that
  \begin{equation*}
    \norm{x_{N_k} - x} < \epsilon - 2^{-j}.
  \end{equation*}
  Then, for all $n \ge N_k$,
  \begin{equation*}
    \norm{x_n - x} \le \norm{x_n - x_{N_k}} + \norm{x_{N_k} - x} < 2^{-k} + \epsilon - 2^{-j} < \epsilon.
  \end{equation*}
  We conclude that every Cauchy sequence in $X$ is convergent, and hence that $X$ is a Banach space.
\end{solution}

\section*{Section 4.2 -- Subspaces and Bases}

\subsection*{Problems}

\subsubsection*{4.2.6}
If a linear vector space is infinite-dimensional, then there exist on it norms that are not equivalent. [\emph{Hint:} Let $\{y_\alpha\}$ be a Hamel basis and define norms by $\norm{x}^2 = \sum_{\alpha} c_\alpha |\lambda_\alpha|^2$, where $x$ has the form (4.2.2) and $c_\alpha$ are positive numbers.]

\begin{solution}
  Let $\{y_\alpha\}_{\alpha \in I}$ be a Hamel basis for an infinite-dimensional linear space $X$. For every $x = \sum_{\alpha \in I} \lambda_\alpha y_\alpha$, define
  \begin{equation*}
    \norm{x}_1 = \left( \sum_{\alpha \in I} |\lambda_\alpha|^2 \right)^{1/2}.
  \end{equation*}
  Then $\norm{\phantom x}_1$ is easily seen to be a norm on $X$.

  Let $\{\alpha_i\}_{i=1}^\infty$ be a countable subset of the index set $I$. Define a set $\{c_\alpha\}_{\alpha \in I}$ of positive constants by $c_{\alpha_i} = 2^{-i}$ for $i = 1,2,\dots$, and $c_{\alpha} = 1$ for $\alpha \notin \{\alpha_i\}$. Define another norm $\norm{\phantom x}_2$ by
  \begin{equation*}
    \norm{x}_2 = \left( \sum_{\alpha \in I} c_\alpha |\lambda_\alpha|^2 \right)^{1/2},
  \end{equation*}
  for $x = \sum_{\alpha \in I} \lambda_\alpha y_\alpha$.

  To see that these two norms are not equivalent, note that
  \begin{equation*}
    \norm{y_{\alpha_i}}_2^2 = c_{\alpha_i} = 2^{-i} = 2^{-i} \norm{y_{\alpha_i}}_1^2
  \end{equation*}
  for all $i$. Hence there exists no $\beta > 0$ such that $\norm{x}_1 \le \beta \norm{x}_2$ for all $x \in X$.
\end{solution}

\section*{Section 4.3 -- Finite-Dimensional Normed Linear Spaces}

\subsection*{Problems}

\subsubsection*{4.3.1}
Let $X$ be a finite-dimensional linear space. Then any two norms on $X$ are equivalent. (According to Problem 4.2.6, the assertion is false if $X$ is infinite-dimensional.)

\begin{solution}
  Let $e_1, \dots, e_n$ be a basis of $X$. For every $x = \sum_{i=1}^n \lambda_i e_i \in X$, let
  \begin{equation*}
    \norm{x}_1 = \sum_{i=1}^n |\lambda_i|.
  \end{equation*}
  It is easily verified that $\norm{\phantom x}_1$ is a norm on $X$. We will show that every norm on $X$ is equivalent to $\norm{\phantom x}_1$, and hence (by transitivity) that any two norms on $X$ are equivalent.

  Given an arbitrary norm $\norm{\phantom x}$, we must prove the existence of positive constants $\alpha$ and $\beta$ such that
  \begin{equation*}
    \alpha \norm{x}_1 \le \norm x \le \beta \norm{x}_1
  \end{equation*}
  for all $x \in X$. These inequalities hold trivially for $x = 0$, so it suffices to consider nonzero $x$. In fact it is sufficient to consider $x$ in the ``$\norm{\phantom x}_1$-sphere'' $S_1 = \{x \in X: \norm{x}_1 = 1\}$, where the inequalities reduce to
  \begin{equation*}
    \alpha \le \norm x \le \beta.
  \end{equation*}
  The inequality for general, nonzero $x$ then follows upon division by $\norm{x}_1$.

  We start by showing that that the map $x \mapsto \norm x$ is continuous with respect to the metric $\rho_1(x,y) = \norm{x - y}_1$. Let $\epsilon > 0$ be given, and write $M = \max(\norm{e_1}, \dots, \norm{e_n})$. Given
  \begin{equation*}
    x = \sum_{i=1}^n \lambda_i e_i, \quad y = \sum_{i=1}^n \mu_i e_i
  \end{equation*}
  satisfying $\rho_1(x,y) < \epsilon/M$, we have
  \begin{equation*}
    \norm{x-y} \le \sum_{i=1}^n |\lambda_i - \mu_i| \, \norm{e_i} \le \sum_{i=1}^n |\lambda_i - \mu_i| \, M = \rho_1(x,y) M < \epsilon,
  \end{equation*}
  and continuity follows.

  The sphere $S_1$ is obviously closed and bounded under $\norm{\phantom x}_1$, hence compact by Theorem 4.3.3. By Theorem 3.6.2 and the continuity established above, the map $x \mapsto \norm x$ attains a maximum and a minimum on $S_1$. Let
  \begin{equation*}
    \alpha = \inf_{x \in S_1} \norm x, \quad \beta = \sup_{x \in S_1} \norm x,
  \end{equation*}
  and note that $\alpha > 0$ since $\norm x = \alpha$ is attained for some nonzero $x$. It follows that $\alpha$ and $\beta$ are positive constants such that $\alpha \le \norm x \le \beta$ for all $x \in S_1$, so we are done.
\end{solution}

\subsubsection*{4.3.2}
Let $Y$ be a finite-dimensional linear subspace of a normed linear space $X$, and let $x_0 \in X$, $x_0 \notin Y$. Then there exists a point $y_0 \in Y$ such that
\begin{equation*}
  \inf_{y \in Y} \norm{x_0 - y} = \norm{x_0 - y_0}.
\end{equation*}

\begin{solution}
  Note that $Y$ is closed by Theorem 4.3.2. Let $L = \inf_{y \in Y} \norm{x_0 - y}$. For $n = 1,2, \dots$, choose $y_n \in Y$ such that
  \begin{equation*}
    \norm{x_0 - y_n} < L + \frac{1}{n}.
  \end{equation*}
  Note that $y_n \in B(x_0, L+1) \cap Y$ for all $n$. This is a bounded subset of $Y$, so by Theorems 4.3.3 and 3.5.4, the sequence $(y_n)$ has a subsequence $(y_{n_k})$ converging to a point
  \begin{equation*}
    y_0 \in \overline{B(x_0, L+1) \cap Y} \subset \overline Y = Y.
  \end{equation*}
  For all $k$ we have
  \begin{equation*}
    \norm{x_0 - y_0} \le \norm{x_0 - y_{n_k}} + \norm{y_{n_k} - y_0}.
  \end{equation*}
  The left-hand side of this inequality is bounded below by $L$, and the right-hand side converges to $L$ as $k \to \infty$. It follows that $\norm{x_0 - y_0} = L$.
\end{solution}

\subsubsection*{4.3.3}
A norm $\norm{\phantom x}$ is said to be \emph{strictly convex} if $\norm x = 1$, $\norm y = 1$, $\norm{x+y} = 2$ imply that $x = y$. Prove that if the norm of $X$ is strictly convex, then the point $y_0$ occurring in the assertion of Problem 4.3.2 is unique.

\begin{solution}
  Let $\norm{\phantom x}$ be a strictly convex norm on a linear space $X$, and let $Y$ be a finite-dimensional linear subspace of $X$. Let $x_0 \in X - Y$,  $L = \inf_{y \in Y} \norm{x_0 - y}$, and suppose that there are elements $y_0, y_0' \in Y$ such that
  \begin{equation*}
    \norm{x_0 - y_0} = \norm{x_0 - y_0'} = L.
  \end{equation*}

  It is clear that $\norm{(x_0 - y_0)/L} = \norm{(x_0 - y_0')/L} = 1$. Moreover,
  \begin{equation*}
    \norm{(x_0 - y_0)/L + (x_0 - y_0')/L} = \frac{2}{L} \norm{x_0 - (y_0 + y_0')/2} \ge \frac{2}{L} L = 2,
  \end{equation*}
  and
  \begin{equation*}
    \norm{(x_0 - y_0)/L + (x_0 - y_0')/L} \le \frac{1}{L} \left( \norm{x_0 - y_0} + \norm{x_0 - y_0'} \right) = \frac{1}{L} 2L = 2,
  \end{equation*}
  so $\norm{(x_0 - y_0)/L + (x_0 - y_0')/L} = 2$. By strict convexity,
  \begin{equation*}
    \frac{1}{L} (x_0 - y_0) = \frac{1}{L} (x_0 - y_0'),
  \end{equation*}
  and it follows that $y_0 = y_0'$.
\end{solution}

\subsubsection*{4.3.4}
Prove that the norm of $L^p(X,\mu)$ is strictly convex if $1 < p < \infty$, and is not strictly convex if $p = 1$ or if $p = \infty$.

\begin{solution}
  Let $f,g \in \sc L^p(X,\mu)$, $1 < p < \infty$, and suppose $\norm{f}_p = \norm{g}_p = 1$ and $\norm{f+g}_p = 2$. We then have equality in Minkowski's inequality:
  \begin{equation*}
    \norm{f+g}_p = \norm{f}_p + \norm{g}_p.
  \end{equation*}
  By Problem 3.2.7 this implies that $f = 0$ a.e., or $g = 0$ a.e., or $f = \lambda g$ a.e.\ for some positive constant $\lambda$. The first two possibilities are ruled out since $\norm{f}_p = \norm{g}_p = 1$, so the third alternative must hold. But then
  \begin{equation*}
    1 = \norm{f}_p = |\lambda| \, \norm{g}_p = |\lambda|,
  \end{equation*}
  so $\lambda = 1$. Thus $f = g$ a.e., so that $\tilde f = \tilde g$ in $L^p(X,\mu)$. It follows that $\norm{\phantom x}_p$ is strictly convex if $1 < p < \infty$.

  For $p = 1, \infty$, surely the problem is supposed to say `not \emph{necessarily} strictly convex', because we can come up with examples where $\norm{\phantom x}_p$ \emph{is} strictly convex, such as an empty measure space $X = \emptyset$, or any space with identically zero measure $\mu = 0$. (Perhaps less trivial examples exist.) Hence we will only demonstrate that there are examples where $\norm{\phantom x}_p$ ($p \in \{1,\infty\}$) is not strictly convex.

  For $p = 1$, consider the $L^1$-space $l^1$. The sequences $x = (1,0,0,\dots)$ and $y = (0,1,0,0,\dots)$ satisfy $\norm{x}_1 = \norm{y}_1 = 1$ and $\norm{x + y}_1 = 2$, yet $x \ne y$. For $p = \infty$, consider the $L^\infty$-space $l^\infty$. The sequences $x = (1,0,0,\dots)$ and $y = (1,1,1,\dots)$ satisfy $\norm{x}_\infty = \norm{y}_\infty = 1$ and $\norm{x+y}_\infty = 2$, but $x \ne y$.
\end{solution}

\subsubsection*{4.3.5}
Prove that in $C[a,b]$ the uniform norm is not equivalent to the $L^p$ norm (for $1 \le p < \infty$).

\begin{solution}
  For simplicity, let $a = 0$ and $b = 1$. For $n = 1,2,\dots$, define ${f_n: [0,1] \to \bb R}$ (or $\bb C$) by $f_n(x) = x^n$. Let $\norm{\phantom x}_u$ denote the uniform norm. For all $n$ we have
  \begin{equation*}
    \norm{f_n}_u = \max_{0 \le x \le 1} |f(x)| = 1
  \end{equation*}
  and
  \begin{equation*}
    \norm{f_n}_p = \left( \int_0^1 x^n dx \right)^{1/p} = (n+1)^{-1/p}.
  \end{equation*}
  (We are assuming that the $L^p$ norm is defined with the standard Lebesgue measure.) In particular $\norm{f_n}_p \to 0$ as $n \to \infty$, whatever the value of $p$ ($\ne \infty$). It follows that there exists no $\beta > 0$ such that $\norm{f}_u \le \beta \norm{f}_p$ for all $f \in C[0,1]$, and hence that the two norms are not equivalent.
\end{solution}

\subsubsection*{4.3.7}
Let $n$ be a positive integer, $1 \le p < \infty$, and let $f(x)$ be a continuous function on $0 \le x \le 1$. Then there exists a unique polynomial $Q_n$ of degree $n$ such that for any other polynomial $P_n$ of degree $n$
\begin{equation*}
  \int_0^1 |f(x) - P_n(x)|^p dx > \int_0^1 |f(x) - Q_n(x)|^p dx.
\end{equation*}

\begin{solution}
  There is an error in the problem statement; it should be polynomials of degree $\le n$, not \emph{exactly} $n$. To see that the written claim is false, consider the case $f(x) = 0$ and $n = 1$. Then $f$ can be approximated arbitrarily closely by degree 1 polynomials $ax + b$, $a \ne 0$, but no such polynomial will make $\norm{f - P}_p$ vanish completely.

  Let $\sc P_n$ denote the set of polynomial functions on $[0,1]$ with degree $\le n$. Then $\sc P_n$ is a linear subspace of the normed linear space $(C[0,1], \norm{\phantom x}_p)$, and is finite-dimensional since it is spanned by the polynomials $1, x, x^2, \dots, x^n$.

  If $f \in \sc P_n$, then $Q = f$ satisfies the claim, since $\norm{f - P}_p > 0$ for all $P \ne f$ (else $\norm{\phantom x}_p$ would not be a norm). If $f \not\in \sc P_n$, then the conclusion of Problem 4.3.2 tells us that there exists $Q \in \sc P_n$ such that
  \begin{equation*}
    \inf_{P \in \sc P_n} \norm{f - P} = \norm{f - Q}.
  \end{equation*}
  This $Q$ is unique by Problem 4.3.3 if the norm $\norm{\phantom x}_p$ is strictly convex, whereupon the claim follows. By Problem 4.3.4 this is the case for $1 < p < \infty$. In fact the norm is strictly convex even for $p = 1$ over $C[0,1]$, as is easily verified directly from the definition.
\end{solution}


\section*{Section 4.4 -- Linear Transformations}

\subsection*{Problems}

\subsubsection*{4.4.2}
Let $T$ be an additive operator [that is, $T(x_1 + x_2) = Tx_1 + Tx_2$] from a real normed linear space $X$ into a normed linear space $Y$. If $T$ is continuous, then $T$ is homogeneous [that is, $T(\lambda x) = \lambda Tx$]. [\emph{Hint:} Prove that $T[(m/n)x] = (m/n)Tx$, where $m,n$ are integers.]

\begin{solution}
  Let $x$ be an arbitrary element of $X$. By induction, additivity implies $T(mx) = m \, Tx$ for positive integers $m$. Moreover,
  \begin{equation*}
    T0 = T(0 + 0) = T0 + T0
  \end{equation*}
  implies that $T0 = 0$, so that
  \begin{equation*}
    0 = T0 = T(mx - mx) = T(mx) + T(-mx),
  \end{equation*}
  which shows that $T(-mx) = -T(mx) = -m \, Tx$, thus extending the earlier result to nonpositive integers. Finally, if $m$ and $n$ are integers, $n \ne 0$, then
  \begin{equation*}
    n \, T \left( \frac{m}{n} x \right) = T \left( n \frac{m}{n} x \right) = T(m x) = m \, Tx,
  \end{equation*}
  so that $T[(m/n)x] = (m/n) Tx$, further extending the result to rationals.

  Now, let $\lambda \in \bb R$. There exists a sequence $(\lambda_n)$ in $\bb Q$ such that $\lambda_n \to \lambda$. Clearly $\lambda_n x \to \lambda x$ in $X$, so $T(\lambda_n x) \to T(\lambda x)$ in $Y$ by continuity of $T$. But, by what we found above,
  \begin{equation*}
    T(\lambda_n x) = \lambda_n \, Tx \to \lambda \, Tx,
  \end{equation*}
  so $T(\lambda x) = \lambda \, Tx$.
\end{solution}

\subsubsection*{4.4.6}
Find the norm of the operator $A \in \sc B(X)$ given by $(Af)(t) = tf(t)$ $(0 \le t \le 1)$, where (a) $X = C[0,1]$, (b) $X = L^p(0,1)$ and ($1 \le p \le \infty$).

\begin{solution}
  \leavevmode
  \begin{enumerate}[label=(\alph*)]
    \item For $0 \le t \le 1$ we have $|tf(t)| = |t| |f(t)| \le |f(t)|$, hence $\norm{Af} \le \norm f$, and
      \begin{equation*}
        \norm A = \sup_{f \ne 0} \frac{\norm{Af}}{\norm f} \le 1.
      \end{equation*}
      The upper bound $\norm{Af} / \norm f = 1$ is attained with $f$ constant, so $\norm A = 1$.

    \item Let us first verify that $A \in \sc B(X)$, i.e.\ that it is a bounded linear operator $L^p(0,1) \to L^p(0,1)$. Linearity is immediate. If $f \in \sc L^p(0,1)$, then $|f|^p$ is integrable, so $|t f(t)|^p = |t|^p |f(t)|^p$ is integrable by Corollary 2.10.2, and we see that $A$ does indeed map into $L^p(0,1)$. Finally, since $|t f(t)|^p = |t|^p |f(t)|^p \le |f(t)|^p$ for $0 < t < 1$, we have $\norm{Af}_p \le \norm{f}_p$, so that $\norm A \le 1$.

      We will now show that $\norm A \ge 1$, so that $\norm A = 1$. The case $p = \infty$ is similar to (a), so we will assume $1 \le p < \infty$. For $n = 1,2,\dots$, define simple functions $f_n: (0,1) \to \bb R$ (or $\bb C$) by
      \begin{equation*}
        f_n(t) =
        \begin{cases}
          0 & \text{if $0 < t < 1 - 1/n$,} \\
          n^{1/p} & \text{if $1 - 1/n \le t < 1$.}
        \end{cases}
      \end{equation*}
      Then one easily finds that $\norm{f_n}_p = 1$ and $\norm{A f_n}_p \ge 1 - 1/n$, so that
      \begin{equation*}
        \norm A \ge \frac{\norm{A f_n}_p}{\norm{f_n}_p} \ge 1 - \frac{1}{n}
      \end{equation*}
      for all $n$. Indeed it follows that $\norm A \ge 1$.
  \end{enumerate}
\end{solution}

\subsubsection*{4.4.7}
A linear operator from a normed linear space $X$ into a normed linear space $Y$ is bounded if and only if it maps bounded sets onto bounded sets.

\begin{solution}
  Let $T: X \to Y$ be a linear operator between normed linear spaces.

  Suppose first that $T$ is bounded, and let $A$ be a bounded subset of $X$. Then $\norm T < \infty$, and there is some $L$ such that $\norm x \le L < \infty$ for all $x \in A$. Hence
  \begin{equation*}
    \norm{Tx} \le \norm T \, \norm x \le \norm T L
  \end{equation*}
  for all $x \in A$, so $T(A)$ is bounded.

  Conversely, suppose that $T$ maps bounded sets onto bounded sets. The set $\{x \in X: \norm x = 1\}$ is bounded, so there exists $M$ such that $\norm{Tx} \le M < \infty$ whenever $\norm x = 1$. It follows that
  \begin{equation*}
    \norm T = \sup_{\norm x = 1} \norm{Tx} \le M,
  \end{equation*}
  and hence that $T$ is bounded.
\end{solution}

\subsubsection*{4.4.8}
A linear operator from a normed linear space $X$ into a normed linear space $Y$ is continuous if and only if it maps sequences converging to 0 into bounded sequences.

\begin{solution}
  Let $T: X \to Y$ be a linear operator between normed linear spaces. The claim is immediate if $X$ is the trivial space (containing only the 0 vector), so let us assume that $X$ is nontrivial.

  Suppose first that $T$ is continuous, and therefore bounded. Any sequence in $X$ converging to 0 is easily seen to be bounded, hence is mapped to a bounded sequence by the conclusion of the previous problem.

  Conversely, suppose $T$ has the property that it maps sequences converging to 0 into bounded sequences. Assume towards a contradiction that $T$ is unbounded. Then it is possible to construct a sequence $(x_n)$ in $X$ such that $\norm{x_n} = 1$ and $\norm{Tx_n} > n$ for every $n$. The sequence $(x_n/\sqrt n)$ converges to 0, so $\{T(x_n/\sqrt n)\}$ is bounded by hypothesis. But
  \begin{equation*}
    \snorm{T \left( \frac{x_n}{\sqrt n} \right)} = \frac{1}{\sqrt n} \norm{Tx_n} > \frac{1}{\sqrt n} \cdot n = \sqrt n \to \infty
  \end{equation*}
  as $n \to \infty$, yielding a contradiction. We conclude that $T$ must be bounded, and thus continuous.
\end{solution}


\section*{Section 4.6 -- The Open-Mapping Theorem and the Closed-Graph Theorem}

\subsection*{Problems}

\subsubsection*{4.6.1}
If $T, S, T^{-1}, S^{-1}$ belong to $\sc B(X)$, then $(TS)^{-1} \in \sc B(X)$ and $(TS)^{-1} = S^{-1} T^{-1}$.

\begin{solution}
  Note in particular that $T, S, T^{-1}, S^{-1}$ belonging to $\sc B(X)$ implies that all of these transformations are bijective, in addition to bounded. (If $T$ is not surjective, then $D_{T^{-1}} = T(X) \ne X$, hence $T^{-1} \notin \sc B(X)$.)

  It is clear that $\norm{TS} \le \norm T \, \norm S < \infty$, hence $TS \in \sc B(X)$, and it is bijective on account of being a composition of bijections. Thus $(TS)^{-1}$ exists and is equal to $S^{-1} T^{-1}$. It follows that $\norm{(TS)^{-1}} \le \norm{S^{-1}} \, \norm{T^{-1}} < \infty$, hence $(TS)^{-1} \in \sc B(X)$.
\end{solution}

\subsubsection*{4.6.2}
Let $X$ be a Banach space and let $A \in \sc B(X)$, $\norm A < 1$. Prove that $(I + A)^{-1}$ exists and is given by
\begin{equation*}
  (I + A)^{-1} = \sum_{n=0}^\infty (-1)^n A^n,
\end{equation*}
where the series is absolutely convergent [in $\sc B(X)$]. Show also that
\begin{equation*}
  \norm{(I + A)^{-1}} \le 1/(1 - \norm A).
\end{equation*}

\begin{solution}
  We note first that
  \begin{equation*}
    \sum_{n=0}^\infty \norm{(-1)^n A^n} = \sum_{n=0}^\infty \norm{A^n} \le \sum_{n=0}^\infty \norm{A}^n = \frac{1}{1 - \norm A},
  \end{equation*}
  since $\norm A < 1$. Hence the series $\sum_{n=0}^\infty (-1)^n A^n$ is strongly convergent to an operator $B \in \sc B(X)$, by Theorem 4.5.2. (Recall that $\sc B(X)$ is a Banach space, hence absolute convergence implies convergence. Convergence in $\sc B(X)$ is the uniform convergence of operators, and uniform convergence implies strong convergence.)

  For all $x \in X$, we have
  \begin{equation*}
    ABx = A \left( \sum_{n=0}^\infty (-1)^n A^n x \right) = \sum_{n=0}^\infty (-1)^n A^{n+1} x = x - \sum_{n=0}^\infty (-1)^n A^n x = (I - B)x,
  \end{equation*}
  where we have used the continuity of $A$ to interchange limiting processes. Also,
  \begin{equation*}
    BAx = \sum_{n=0}^\infty (-1)^n A^{n+1} x = ABx.
  \end{equation*}
  It follows that
  \begin{equation*}
    B(I+A) = (I+A)B = B + AB = B + I - B = I,
  \end{equation*}
  so that $B = (I + A)^{-1}$.

  Finally,
  \begin{equation*}
    \norm{(I + A)^{-1}} \le \sum_{n=0}^\infty \norm{(-1)^n A^n} \le \frac{1}{1 - \norm A}
  \end{equation*}
  by what we found earlier.
\end{solution}

\subsubsection*{4.6.3}
Let $X$ be a Banach space and let $T$ and $T^{-1}$ belong to $\sc B(X)$. Prove that if $S \in \sc B(X)$ and $\norm{S - T} < 1/\norm{T^{-1}}$, then $S^{-1}$ exists and is a bounded operator, and
\begin{equation*}
  \norm{S^{-1} - T^{-1}} < \frac{\norm{T^{-1}}}{1 - \norm{S - T} \, \norm{T^{-1}}}.
\end{equation*}
[\emph{Hint:} $S = [(S-T)T^{-1} + I]T$.]

\begin{solution}
  Note that $S T^{-1} = I + (S-T)T^{-1}$, and that
  \begin{equation*}
    \norm{(S-T)T^{-1}} \le \norm{S-T} \norm{T^{-1}} < 1.
  \end{equation*}
  By the previous problem $(ST^{-1})^{-1}$ exists, and
  \begin{equation*}
    \norm{(ST^{-1})^{-1}} \le \frac{1}{1 - \norm{(S-T)T^{-1}}} \le \frac{1}{1 - \norm{(S-T)} \, \norm{T^{-1}}}.
  \end{equation*}
  Moreover, since $ST^{-1}(ST^{-1})^{-1} = I$ and
  \begin{equation*}
    T^{-1}(ST^{-1})^{-1}S = T^{-1}(ST^{-1})^{-1}ST^{-1}T = T^{-1}T = I,
  \end{equation*}
  we have $S^{-1} = T^{-1}(ST^{-1})^{-1}$. Finally,
  \begin{equation*}
    \norm{S^{-1}} = \norm{T^{-1}(ST^{-1})^{-1}} \le \norm{T^{-1}} \, \norm{(ST^{-1})^{-1}} \le \frac{\norm{T^{-1}}}{1 - \norm{(S-T)} \, \norm{T^{-1}}},
  \end{equation*}
  and
  \begin{equation*}
    \norm{S^{-1} - T^{-1}} = \norm{S^{-1}(S - T)T^{-1}} \le \norm{S^{-1}} \, \norm{S-T} \, \norm{T^{-1}} < \norm{S^{-1}},
  \end{equation*}
  so that
  \begin{equation*}
    \norm{S^{-1} - T^{-1}} < \frac{\norm{T^{-1}}}{1 - \norm{(S-T)} \, \norm{T^{-1}}}.
  \end{equation*}
\end{solution}

\subsubsection*{4.6.4}
Let $X$ and $Y$ be two linear vector spaces. Find necessary and sufficient conditions for a subset $G$ of $X \times Y$ to be the graph of a linear operator from $X$ into $Y$.

\begin{solution}
  We claim that $G$ is the graph of a linear operator from $X$ into $Y$ if and only if
  \begin{enumerate}[label=(\roman*)]
    \item $G$ is a linear subspace of $X \times Y$.
    \item The set $G \cap (\{0\} \times Y)$ is a singleton.
  \end{enumerate}
  It is clear that these conditions are necessary, so we need only prove that they are sufficient.

  Since $G$ is nonempty by (ii), it contains an element $(x,y)$. By (i) it also contains $(0,0) = 0 \cdot (x,y)$, and it follows that $G \cap (\{0\} \times Y) = \{(0,0)\}$.

  If $(u,v), (u,v') \in G$, then
  \begin{equation*}
    (0, v - v') = (u,v) - (u,v') \in G \cap (\{0\} \times Y)
  \end{equation*}
  by (i). It follows that $(0, v - v') = (0,0)$, hence that $v = v'$.

  By the above, $G$ is a functional relation on $X \times Y$, so it defines a partial function $T: D \subset X \to Y$, where
  \begin{equation*}
    D = \{x \in X; \, \text{$\exists y \in Y$ such that $(x,y) \in G$}\},
  \end{equation*}
  and $T(x) = y$ if $(x,y) \in G$.

  Suppose $x_1, x_2 \in D$, and $\lambda_1, \lambda_2$ are scalars. Then
  \begin{equation*}
    (\lambda_1 x_1 + \lambda_2 x_2, \lambda_1 T(x_1) + \lambda_2 T(x_2)) = \lambda_1 (x_1, T(x_1)) + \lambda_2 (x_2, T(x_2)) \in G
  \end{equation*}
  by (i). Hence $\lambda_1 x_1 + \lambda_2 x_2 \in D$, which shows that $D$ is a linear subspace of $X \times Y$, and
  \begin{equation*}
    T(\lambda_1 x_1 + \lambda_2 x_2) = \lambda_1 T(x_1) + \lambda_2 T(x_2),
  \end{equation*}
  so that $T$ is a linear operator.

  Finally, note that $G$ is precisely the graph of $T$. This completes the proof.
\end{solution}

\subsubsection*{4.6.5}
Let $X$ and $Y$ be Banach spaces and let $T$ be a bounded linear map from $X$ into $Y$. If $T(X)$ is of the second category (in $Y$), then $T(X) = Y$.

\begin{solution}
  We will use the following lemma:
  \begin{quote}
    If $W$ is a linear subspace of a normed space $V$, and if $W$ contains a nonempty open subset of $V$, then $W = V$.
  \end{quote}
  To see that this is true, note that $W$ contains an open ball $B(x_0,r)$. Given any $y \in V$, let
  \begin{equation*}
    x = \frac{r}{2 \norm y} y + x_0.
  \end{equation*}
  Then $x \in B(x_0,r) \subset W$, so that
  \begin{equation*}
    y = \frac{2 \norm y}{r} (x - x_0) \in W
  \end{equation*}
  by closure under linear combinations.

  Now, assume that $T(X)$ is of the second category, and follow the steps of parts (a) and (b) of the proof of Theorem 4.6.1, but with $T(X)$ in place of $Y$. We find that $T(X)$ contains an open ball (see equation (4.6.2)) and hence that $T(X) = Y$ by our lemma.
\end{solution}

\subsubsection*{4.6.6}
Let $X$ and $Y$ be Banach spaces and let $T$ be a linear map from a linear subspace $D_T$ of $X$ into $Y$. If $D_T$ (in $X$) and the graph of $T$ (in $X \times Y$) are closed, then $T$ is bounded---that is, $\norm{Tx} \le K \norm x$ for all $x \in D_T$ ($K$ constant).

\begin{solution}
  Note first that $D_T$ is complete; this is true for any closed subset of any complete space. Indeed, if $(x_n)$ is a Cauchy sequence in $D_T$, then it is also a Cauchy sequence in $X$, so it converges to a point $x \in X$, and since $D_T$ is closed we have $x \in D_T$. It follows that $D_T$ is a Banach space. Hence we can regard $T$ as a map $D_T \to Y$ and apply Theorem 4.6.4 to conclude that $T$ is continuous, thus bounded by Theorem 4.4.2.
\end{solution}

\subsubsection*{4.6.7}
Let $X$ be a normed linear space with any one of two norms $\norm{\phantom x}_1$, $\norm{\phantom x}_2$. If $\norm{x_n}_2 \to 0$ implies $\norm{x_n}_1 \to 0$, then (4.6.5) holds.

\begin{solution}
  Assume towards a contradiction that (4.6.5) does not hold. Then, for every $n \in \{1, 2, \dots\}$, there exists $x_n \in X$ such that $\norm{x_n}_1 > n \norm{x_n}_2$. The sequence $y_n = x_n / (n \norm{x_n}_2)$ satisfies
  \begin{equation*}
    \norm{y_n}_1 = \frac{\norm{x_n}_1}{n \norm{x_n}_2} > \frac{n \norm{x_n}_2}{n \norm{x_n}_2} = 1
  \end{equation*}
  for all $n$. But $\norm{y_n}_2 = 1/n \to 0$, which by hypothesis implies $\norm{y_n}_1 \to 0$, yielding a contradiction.
\end{solution}


\section*{Section 4.8 -- The Hahn-Banach Theorem}

\subsection*{Problems}

\subsubsection*{4.8.1}
Let $X$ be a normed linear space and let $\{x_n\} \subset X$. A point $y_0$ is the limit of linear combinations $\sum_{j=1}^n c_j x_j$ if and only if $x^*(y_0) = 0$ for all $x^*$ for which $x^*(x_j) = 0$ for $1 \le j < \infty$.

\begin{solution}
  Note that ``$y_0$ is the limit of linear combinations $\sum_{j=1}^n c_j x_j$'' is not meant to imply $y_0 = \lim_{n \to \infty} \sum_{j=1}^n c_j x_j$ for some sequence of coefficients $(c_j)$. Rather, it just says that $y_0$ is the limit of a sequence of finite linear combinations of elements in $\{x_n\}$; i.e., that $y_0$ is a limit point of $S := \vspan\{x_n\}$. Also, the statement ``$x^*(x_j) = 0$ for $1 \le j < \infty$'' can be simplified to ``$x^*$ vanishes on $S$.''

  Suppose that $y_0$ is a limit point of $S$. Then there is a sequence $(s_n)$ in $S$ such that $s_n \to y_0$. If $x^* \in X^*$ vanishes on $S$, then
  \begin{equation*}
    x^*(y_0) = x^*\left( \lim_{n \to \infty} s_n \right) = \lim_{n \to \infty} x^*(s_n) = 0
  \end{equation*}
  by continuity of $x^*$.

  Conversely, suppose that $x^*(y_0) = 0$ for all $x^* \in X^*$ that vanish on $S$. Let
  \begin{equation*}
    d = \inf_{s \in S} \norm{s - y_0}.
  \end{equation*}
  If $d > 0$, then Theorem 4.8.3 tells us that there exists $x^* \in X^*$ such that $x^*(y_0) = 1$, but which vanishes on $S$. This contradicts our assumptions, so we conclude that $d = 0$, which in turn shows that $y_0$ is a limit point of $S$.
\end{solution}

\subsubsection*{4.8.5}
Let $X$ be an infinite-dimensional Banach space. Prove that there exists an infinite, strictly decreasing sequence $\{Y_n\}$ of infinite-dimensional closed linear subspaces of $X$. [\emph{Hint:} Take $Y_1$ to be the null space of some $x_1^* \ne 0$ in $X^*$. Take $Y_2$ to be the null space of some $x_2^* \ne 0$ in $Y_1^*$, and so on.]

\begin{solution}
  We will construct such a sequence by induction. For the base case, let $Y_0 = X$. Certainly $Y_0$ is an infinite-dimensional closed linear subspace of $X$.

  For the inductive step, assume that we have infinite-dimensional closed linear subspaces $Y_0 \supset Y_1 \supset \dots \supset Y_n$, with the inclusions being strict. Fix an element $x_0 \in Y_n$ such that $\norm{x_0} = 1$. (Such an element is guaranteed to exist since $Y_n$ is infinite-dimensional.) Corollary 4.8.4 provides a continuous linear functional $x^* \in Y_n$ such that $x^*(x_0) = 1$. Let $Y_{n+1}$ be the null space of $x^*$; clearly a proper linear subspace of $Y_n$, hence also of $X$. As discussed after Corollary 4.8.7, each element $x \in Y_n$ can be written as $x = z + \lambda x_0$, where $\lambda = x^*(x)$ and $z = x - \lambda x_0 \in Y_{n+1}$. It follows that $Y_{n+1}$ is infinite-dimensional. Finally, if $(y_i)$ is a sequence in $Y_{n+1}$ and $y_i \to y \in X$, then $x^*(y) = \lim_{i \to \infty} x^*(y_i) = 0$ by continuity, so $y \in Y_{n+1}$, making $Y_{n+1}$ a closed subset of $X$. This concludes the inductive step.
\end{solution}

\subsubsection*{4.8.9}
Let $u(t)$ be a function defined on $a < t < b$ with values in a Banach space $X$. We say that $u(t)$ is \emph{strongly differentiable at $t$} [\emph{on $(a,b)$}] if $\lim_{h \to 0} \{[u(t+h) - u(t)]/h\}$ exists [for all $t \in (a,b)$]. The limit is denoted by $du(t)/dt$ and is called the derivative of $u(t)$. For functions $A(t)$ with values in $\sc B(X)$, if $\lim_{h \to 0} \{[A(t+h)x - A(t)x]/h\}$ exists for any $x \in X$, then we say that $A(t)$ has a \emph{strong derivative}. If $\lim_{h \to 0} \{[A(t+h)-A(t)]/h\}$ exists (in the uniform topology), then we say that $A(t)$ is \emph{uniformly differentiable}. Prove that $e^{tA}$ [$A \in \sc B(X)$] is uniformly differentiable and $de^{tA}/dt = A e^{tA}$.

\begin{solution}
  First note that, given any $t \in \bb R$,
  \begin{equation*}
    \sum_{n=0}^\infty \snorm{\frac{(tA)^n}{n!}} \le \sum_{n=0}^\infty \frac{(|t|^n \norm{A}^n)}{n!} = e^{|t| \, \norm A} < \infty,
  \end{equation*}
  so that the series $\sum_{n=0}^\infty (tA)^n/(n!)$ is strongly convergent (to an operator) in $\sc B(X)$ (c.f.\ Theorems 4.1.2, 4.5.2). Hence we can define a map $E_A: \bb R \to \sc B(X)$ by $E_A(t) = \sum_{n=0}^\infty (tA)^n/(n!)$. Instead of $E_A(t)$ we typically write $e^{tA}$.

  With a little work we find that
  \begin{equation*}
    \frac{e^{(t+h)A} - e^{tA}}{h} - A e^{tA} = \sum_{n=2}^\infty \frac{1}{n!} \frac{(t+h)^n - t^n - nht^{n-1}}{h} A^n.
  \end{equation*}
  Further simplification with the binomial formula yields
  \begin{equation*}
    \frac{(t+h)^n - t^n - nht^{n-1}}{h} = \sum_{k=2}^n \binom{n}{k} t^{n-k} h^{k-1}.
  \end{equation*}
  Hence
  \begin{equation*}
    \snorm{\frac{e^{(t+h)A} - e^{tA}}{h} - A e^{tA}} \le \sum_{n=2}^\infty \frac{\norm{A}^n}{n!} \sum_{k=2}^n \binom{n}{k} |t|^{n-k} |h|^{k-1}.
  \end{equation*}
  If $t = 0$, then the right-hand side becomes
  \begin{equation*}
    |h| \cdot \norm{A}^2 \sum_{n=0}^\infty \frac{(|h| \, \norm{A})^n}{(n+2)!} \le |h| \, \norm{A}^2 \, e^{|h| \, \norm{A}},
  \end{equation*}
  which goes to zero as $h \to 0$. If $t \ne 0$, then
  \begin{equation*}
    \sum_{k=2}^n \binom{n}{k} |t|^{n-k} |h|^{k-1} \le |h| \, |t|^{n-2} \sum_{k=2}^n \binom{n}{k} = |h| \, |t|^{n-2} \, 2^n
  \end{equation*}
  whenever $|h| \le |t|$, yielding
  \begin{equation*}
    \snorm{\frac{e^{(t+h)A} - e^{tA}}{h} - A e^{tA}} \le \frac{|h|}{|t|^2} \sum_{n=2}^\infty \frac{(2 \, |t| \, \norm{A})^n}{n!} \le \frac{|h|}{|t|^2} e^{2 \, |t| \, \norm A}
  \end{equation*}
  for sufficiently small $h$, which also goes to zero as $h \to 0$. It follows that $e^{tA}$ is uniformly differentiable on $\bb R$, with derivative $A e^{tA}$.
\end{solution}

\subsubsection*{4.8.10}
Let $X$ be a real normed linear space, and let $u(t)$ be continuous and strongly differentiable in $(a,b)$. Then for any $a < \alpha < \beta < b$,
\begin{equation*}
  \norm{u(\beta) - u(\alpha)} \le (\beta - \alpha) \sup_{\alpha \le t \le \beta} \snorm{\frac{du(t)}{dt}}.
\end{equation*}
[\emph{Hint:} Apply $x^*$ to $u(\beta) - u(\alpha)$.]

\begin{solution}
  If $u(\alpha) = u(\beta)$ then there is nothing to prove, so assume $u(\beta) \ne u(\alpha)$. By Corollary 4.8.4 there is a bounded linear operator $x^* \in X^*$ such that $\norm{x^*} = 1$ and $x^*(u(\beta) - u(\alpha)) = \norm{u(\beta) - u(\alpha)}$. Define $f = x^* \circ u: (a,b) \to \bb R$. Since $x^*$ is linear and continuous,
  \begin{equation*}
    \lim_{h \to 0} \frac{f(t+h) - f(t)}{h} = \lim_{h \to 0} x^* \left[ \frac{u(t+h) - u(h)}{h} \right] = x^* \left[ \lim_{h \to 0} \frac{u(t+h) - u(h)}{h} \right],
  \end{equation*}
  so that $f$ is differentiable with derivative
  \begin{equation*}
    \frac{df(t)}{dt} = x^* \left[ \frac{du(t)}{dt} \right].
  \end{equation*}
  By the mean value theorem from elementary real analysis, we have
  \begin{equation*}
    f(\beta) - f(\alpha) = (\beta - \alpha) \frac{df(\gamma)}{dt}
  \end{equation*}
  for some $\gamma \in (\alpha, \beta)$. Thus,
  \begin{equation*}
    \begin{split}
      \norm{u(\beta) - u(\alpha)} &= x^*(u(\beta) - u(\alpha)) \\
      &= f(\beta) - f(\alpha) \\
      &= (\beta - \alpha) \frac{df(\gamma)}{dt} \\
      &= (\beta - \alpha) x^* \left[ \frac{du(\gamma)}{dt} \right] \\
      &\le (\beta - \alpha) \norm{x^*} \cdot \snorm{\frac{du(\gamma)}{dt}} \\
      &\le (\beta - \alpha) \sup_{\alpha \le t \le \beta} \snorm{\frac{du(t)}{dt}}.
    \end{split}
  \end{equation*}
\end{solution}

\subsubsection*{4.8.12}
For every normed linear space $X$ there is a set $A$ such that $X$ is isomorphic to a subspace of the Banach space of functions $f$ on $A$ with norm $\norm f = \sup_{t \in A} |f(t)|$. If $X$ is separable, $A$ is countable. [\emph{Hint:} Let $\{x_\alpha: \alpha \in A\}$ be dense in $X$. Let $f(x,\alpha)$ be the bounded linear functional (in $x \in X$) satisfying $\norm{f(\, . \,,\alpha)} = 1$, $f(x_\alpha, \alpha) = \norm{x_\alpha}$. Define the isomorphism $x \to g_x(\alpha)$, where $g_x(\alpha) = f(x, \alpha)$. Prove: $\big| |f(x,\alpha)| - \norm x \big| \le 2 \norm{x_\alpha - x}$.]

\begin{solution}
  The conclusion is immediate if $X$ is a trivial space, so assume $X \ne \{0\}$. Let $\{x_\alpha\}_{\alpha \in A}$ be any dense subset of $X$ (possibly $X$ itself), indexed by a set $A$. (Recall that any space can be indexed by itself.) For each $\alpha \in A$, Corollary 4.8.4 fashions a bounded linear functional $f_\alpha \in X^*$ such that $\norm{f_\alpha} = 1$ and $f_\alpha(x_\alpha) = \norm{x_\alpha}$.

  For each $x \in X$, define $g_x: A \to \bb F$ (where $\bb F$ is the field associated with $X$) by $g_x(\alpha) = f_\alpha(x)$. We will prove the following properties of the functions $g_x$:
  \begin{enumerate}[label=(\roman*)]
    \item If $x, y \in X$ and $\lambda, \mu \in \bb F$, then $\lambda g_x + \mu g_y = g_{\lambda x + \mu y}$.
    \item Each function $g_x$ is bounded, with $\sup_{\alpha \in A} |g_x(\alpha)| = \norm x$.
  \end{enumerate}

  To prove (i), simply let $\alpha \in A$ and compute
  \begin{equation*}
    (\lambda g_x + \mu g_y)(\alpha) = \lambda g_x(\alpha) + \mu g_y(\alpha) = \lambda f_\alpha(x) + \mu f_\alpha(y) = f_\alpha(\lambda x + \mu y) = g_{\lambda x + \mu y}(\alpha),
  \end{equation*}
  using the linearity of $f_\alpha$.

  Proving (ii) takes more work. Note first that
  \begin{equation*}
    \sup_{\alpha \in A} |g_x(\alpha)| = \sup_{\alpha \in A} |f_\alpha(x)| \le \sup_{\alpha \in A} \norm{f_\alpha} \, \norm x = \norm x.
  \end{equation*}
  Next, given any $\epsilon > 0$, fix $\alpha' \in A$ such that $\norm{x_{\alpha'} - x} < \epsilon/2$. (This is possible because $\{x_\alpha\}_{\alpha \in A}$ is dense in $X$.) By the triangle inequality,
  \begin{equation*}
    \norm x \le \big| \norm x - \norm{x_{\alpha'}} \big| + \big| \norm{x_{\alpha'}} - |f_{\alpha'}(x)| \big| + |f_{\alpha'}(x)|.
  \end{equation*}
  Now, the ``reverse triangle inequality'' yields
  \begin{equation*}
    \big| \norm x - \norm{x_{\alpha'}} \big| \le \norm{x_{\alpha'} - x} < \frac{\epsilon}{2}
  \end{equation*}
  and
  \begin{equation*}
    \begin{split}
      \big| \norm{x_{\alpha'}} - |f_{\alpha'}(x)| \big| &\le \big| \norm{x_{\alpha'}} - f_{\alpha'}(x) \big| \\
      &= |f_{\alpha'}(x_{\alpha'}) - f_{\alpha'}(x)| \\
      &= |f_{\alpha'}(x_{\alpha'} - x)| \\
      &\le \norm{f_{\alpha'}} \, \norm{x_{\alpha'} - x} \\
      &= \norm{x_{\alpha'} - x} \\
      &< \frac{\epsilon}{2}.
    \end{split}
  \end{equation*}
  Also,
  \begin{equation*}
    |f_{\alpha'}(x)| \le \sup_{\alpha \in A} |f_\alpha(x)| = \sup_{\alpha \in A} |g_x(\alpha)|.
  \end{equation*}
  Putting it all together, we have
  \begin{equation*}
    \norm x \le \sup_{\alpha \in A} |g_x(\alpha)| + \epsilon,
  \end{equation*}
  and since this holds for every $\epsilon$ we finally arrive at (ii).

  Let $F_A$ be the Banach space of all bounded functions $A \to \bb F$, with the supremum norm $\norm g = \sup_{\alpha \in A} |g(\alpha)|$. Since the functions $g_x$ are bounded by (ii), we can define a map $\sigma: X \to F_A$ by $\sigma(x) = g_x$. The image of $\sigma$ is a linear subspace of $F_A$ by (i). Moreover, $\sigma$ is an imbedding, since
  \begin{equation*}
    \norm{\sigma(x) - \sigma(y)} = \norm{g_x - g_y} = \norm{g_{x-y}} = \sup_{\alpha \in A} |g_{x-y}(\alpha)| = \norm{x - y}
  \end{equation*}
  for all $x,y \in X$, by (i) and (ii). Every imbedding injective, so $\sigma$ is an isomorphism (in the sense of Section 3.3) onto its image.

  Finally, if $X$ is separable, then we can take $A$ to be countable.
\end{solution}


\chapter*{Chapter 6 -- Hilbert Spaces and Spectral Theory}

\section*{Section 6.2 -- The Projection Theorem}

\subsection*{Problems}

\subsubsection*{6.2.1}
If $M$ and $N$ are closed linear spaces and $M \perp N$, then $M \oplus N$ is a closed linear space.

\begin{solution}
  We start by noting that an analogue of the Pythagorean theorem holds in Hilbert spaces, and in fact more generally in inner product spaces. Namely, if $u \perp v$ then
  \begin{equation*}
    \norm{u+v}^2 = (u+v,u+v) = (u,u) + (u,v) + (v,u) + (v,v) = \norm{u}^2 + \norm{v}^2.
  \end{equation*}

  We will assume that $M, N \subset H$, with $H$ a Hilbert space. It is clear that $M \oplus N$ is a linear subspace, so it remains only to show that it is closed. Let $(x_n)$ be a sequence in $M \oplus N$ with limit $x \in H$. For each $n$ we have $x_n = y_n + z_n$ for some $y_n \in M$ and $z_n \in N$, and $x = y + z$ for some $y \in M$ and $z \in M^\perp$ by the projection theorem (Theorem 6.2.2). Note that $y_n - y \in M$ and $z_n - z \in M^\perp$, so that $(y_n - y) \perp (z_n - z)$. Thus
  \begin{equation*}
    \norm{z_n - z} \le \norm{y_n - y + z_n - z} = \norm{x_n - x}
  \end{equation*}
  by the analogue of the Pythagorean theorem with $u = y_n - y$ and $v = z_n - z$. It follows that $z_n \to z$, so that $z \in N$ since $N$ is closed. This in turn means that $x \in M \oplus N$, hence that $M \oplus N$ is closed.
\end{solution}

\subsubsection*{6.2.2}
Let $M$ be any subset of a Hilbert space $H$. Then $(M^\perp)^\perp$ is the closed linear space spanned by $M$.

\begin{solution}
  We begin with a small lemma:
  \begin{quote}
    If $C$ is a closed linear subspace of a Hilbert space, then $(C^\perp)^\perp = C$.
  \end{quote}
  Indeed, it is clear that $C \subset (C^\perp)^\perp$. Conversely, suppose $x \in (C^\perp)^\perp$. By the projection theorem $x = y + z$ for some $y \in C$ and $z \in C^\perp$. But
  \begin{equation*}
    \norm{z}^2 = (z,z) = (x-y,z) = (x,z) - (y,z) = 0
  \end{equation*}
  by orthogonality, so $z = 0$ and $x = y \in C$. Hence $(C^\perp)^\perp \subset C$, and the lemma follows.

  Note that ``the closed linear space spanned by $M$'' is the intersection of all linear subspaces of $H$ that contain $M$ (by definition; see Section 4.2). Let us denote this subspace by $C$. We immediately see that $C \subset (M^\perp)^\perp$, since the latter is a closed linear subspace containing $M$. Moreover, since $M \subset C$, we have $C^\perp \subset M^\perp$. By taking orthogonal complements once more and applying the lemma, we obtain
  \begin{equation*}
    (M^\perp)^\perp \subset (C^\perp)^\perp = C,
  \end{equation*}
  thus proving that $(M^\perp)^\perp = C$.
\end{solution}

\end{document}
